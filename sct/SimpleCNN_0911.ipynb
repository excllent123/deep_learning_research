{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "WARNING (theano.gof.compilelock): Overriding existing lock by dead process '9764' (I am process '12188')\n",
      "DEBUG: nvcc STDOUT mod.cu\n",
      "   Creating library C:/Users/kentc/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-Intel64_Family_6_Model_94_Stepping_3_GenuineIntel-2.7.12-64/tmpxhmp6a/265abc51f7c376c224983485238ff1a5.lib and object C:/Users/kentc/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-Intel64_Family_6_Model_94_Stepping_3_GenuineIntel-2.7.12-64/tmpxhmp6a/265abc51f7c376c224983485238ff1a5.exp\n",
      "\n",
      "Using gpu device 0: GeForce GTX 970M (CNMeM is disabled, cuDNN 5103)\n",
      "C:\\Users\\kentc\\Anaconda2\\lib\\site-packages\\theano\\sandbox\\cuda\\__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "import os, sys, progressbar, argparse \n",
    "import commentjson as json\n",
    "from keras.datasets import cifar10\n",
    "from imutils import paths\n",
    "from skimage.io import imread\n",
    "import imageio\n",
    "import cv2\n",
    "\n",
    "from ipywidgets import interact, interactive, fixed\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import SGD\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def error_rate(predictions, labels):\n",
    "  \"\"\"Return the error rate and confusions.\"\"\"\n",
    "  correct = numpy.sum(numpy.argmax(predictions, 1) == numpy.argmax(labels, 1))\n",
    "  total = predictions.shape[0]\n",
    "\n",
    "  error = 100.0 - (100 * float(correct) / float(total))\n",
    "\n",
    "  confusions = numpy.zeros([10, 10], numpy.float32)\n",
    "  bundled = zip(numpy.argmax(predictions, 1), numpy.argmax(labels, 1))\n",
    "  for predicted, actual in bundled:\n",
    "    confusions[predicted, actual] += 1\n",
    "    \n",
    "  return error, confusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def simpleNN(nb_classes,img_rows,img_cols,img_channels):\n",
    "    #####Fail\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, input_shape=(img_channels, img_rows, img_cols)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(nb_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "    sgd = SGD(lr=1e-2, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def simpleCNN(nb_classes, nb_filters,nb_conv,nb_pool,img_rows,img_cols,img_channels, Dense_Before_Out=12):\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(nb_filters, nb_conv, nb_conv,\n",
    "                        border_mode='valid',\n",
    "                        input_shape=(img_channels, img_rows, img_cols)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Convolution2D(nb_filters, nb_conv, nb_conv))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(nb_pool, nb_pool)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(Dense_Before_Out))\n",
    "    model.add(Activation('tanh'))\n",
    "    \n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(nb_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "    sgd = SGD(lr=1e-2, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def simpleCNN_2(nb_classes, nb_filters,nb_conv,nb_pool,img_rows,img_cols,img_channels, Dense_Before_Out=32):\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(nb_filters, nb_conv, nb_conv,\n",
    "                        border_mode='valid',\n",
    "                        input_shape=(img_channels, img_rows, img_cols)))\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(Convolution2D(nb_filters, nb_conv, nb_conv))\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(MaxPooling2D(pool_size=(nb_pool, nb_pool)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(10*Dense_Before_Out, init='lecun_uniform'))\n",
    "    model.add(Activation('tanh'))    \n",
    "    \n",
    "    model.add(Dense(Dense_Before_Out, init='lecun_uniform'))\n",
    "    model.add(Activation('tanh'))\n",
    "    \n",
    "    model.add(Dense(nb_classes, init='lecun_uniform'))\n",
    "    model.add(Activation('softmax'))\n",
    "    sgd = SGD(lr=1e-2, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def simpleCNN_3(nb_classes, nb_filters,nb_conv,nb_pool,img_rows,img_cols,img_channels, Dense_Before_Out=520):\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(nb_filters, nb_conv, nb_conv,\n",
    "                        border_mode='valid',\n",
    "                        input_shape=(img_channels, img_rows, img_cols)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Convolution2D(nb_filters, nb_conv, nb_conv))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(nb_pool, nb_pool)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(Dense_Before_Out,))\n",
    "    model.add(Activation('tanh'))\n",
    "    \n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(Dense_Before_Out,))\n",
    "    model.add(Activation('tanh'))\n",
    "    \n",
    "    model.add(Dense(nb_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "    #sgd = SGD(lr=1e-2, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adadelta',\n",
    "              metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper-parameter Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "batch_size = 32\n",
    "nb_classes = 10\n",
    "nb_epoch = 150\n",
    "data_augmentation = True\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 32, 32\n",
    "# the CIFAR10 images are RGB\n",
    "img_channels = 3\n",
    "\n",
    "nb_filters = 62\n",
    "# size of pooling area for max pooling\n",
    "nb_pool = 2\n",
    "# convolution kernel size\n",
    "nb_conv = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (50000L, 3L, 32L, 32L)\n",
      "Y_train shape: (50000L, 1L)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('Y_train shape:', y_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_11 (Convolution2D) (None, 62, 30, 30)    1736        convolution2d_input_6[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_22 (Activation)       (None, 62, 30, 30)    0           convolution2d_11[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_12 (Convolution2D) (None, 62, 28, 28)    34658       activation_22[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_23 (Activation)       (None, 62, 28, 28)    0           convolution2d_12[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_6 (MaxPooling2D)    (None, 62, 14, 14)    0           activation_23[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)             (None, 62, 14, 14)    0           maxpooling2d_6[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)              (None, 12152)         0           dropout_11[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dense_12 (Dense)                 (None, 520)           6319560     flatten_6[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_24 (Activation)       (None, 520)           0           dense_12[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)             (None, 520)           0           activation_24[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dense_13 (Dense)                 (None, 520)           270920      dropout_12[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_25 (Activation)       (None, 520)           0           dense_13[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_14 (Dense)                 (None, 10)            5210        activation_25[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_26 (Activation)       (None, 10)            0           dense_14[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 6632084\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = simpleCNN_3(nb_classes, nb_filters,nb_conv,nb_pool,img_rows,img_cols, img_channels)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/150\n",
      "50000/50000 [==============================] - 135s - loss: 2.3565 - acc: 0.0984 - val_loss: 2.3443 - val_acc: 0.1000\n",
      "Epoch 2/150\n",
      "50000/50000 [==============================] - 131s - loss: 2.3289 - acc: 0.0990 - val_loss: 2.3339 - val_acc: 0.1000\n",
      "Epoch 3/150\n",
      "50000/50000 [==============================] - 132s - loss: 2.3293 - acc: 0.1002 - val_loss: 2.3602 - val_acc: 0.1000\n",
      "Epoch 4/150\n",
      "50000/50000 [==============================] - 134s - loss: 2.3290 - acc: 0.1011 - val_loss: 2.3648 - val_acc: 0.1000\n",
      "Epoch 5/150\n",
      "50000/50000 [==============================] - 134s - loss: 2.3293 - acc: 0.0983 - val_loss: 2.3425 - val_acc: 0.1000\n",
      "Epoch 6/150\n",
      "50000/50000 [==============================] - 140s - loss: 2.3281 - acc: 0.0990 - val_loss: 2.3456 - val_acc: 0.1000\n",
      "Epoch 7/150\n",
      "50000/50000 [==============================] - 140s - loss: 2.3279 - acc: 0.1026 - val_loss: 2.3496 - val_acc: 0.1000\n",
      "Epoch 8/150\n",
      "50000/50000 [==============================] - 140s - loss: 2.3288 - acc: 0.0987 - val_loss: 2.3711 - val_acc: 0.1000\n",
      "Epoch 9/150\n",
      "50000/50000 [==============================] - 140s - loss: 2.3293 - acc: 0.0980 - val_loss: 2.3670 - val_acc: 0.1000\n",
      "Epoch 10/150\n",
      "50000/50000 [==============================] - 142s - loss: 2.3284 - acc: 0.0993 - val_loss: 2.3580 - val_acc: 0.1000\n",
      "Epoch 11/150\n",
      "50000/50000 [==============================] - 140s - loss: 2.3286 - acc: 0.0996 - val_loss: 2.3615 - val_acc: 0.1000\n",
      "Epoch 12/150\n",
      "50000/50000 [==============================] - 140s - loss: 2.3285 - acc: 0.0983 - val_loss: 2.3728 - val_acc: 0.1000\n",
      "Epoch 13/150\n",
      "50000/50000 [==============================] - 140s - loss: 2.3291 - acc: 0.0994 - val_loss: 2.3477 - val_acc: 0.1000\n",
      "Epoch 14/150\n",
      "50000/50000 [==============================] - 139s - loss: 2.3243 - acc: 0.1032 - val_loss: 2.3704 - val_acc: 0.1000\n",
      "Epoch 15/150\n",
      "50000/50000 [==============================] - 140s - loss: 2.3029 - acc: 0.1188 - val_loss: 2.2948 - val_acc: 0.1132\n",
      "Epoch 16/150\n",
      "50000/50000 [==============================] - 139s - loss: 2.2444 - acc: 0.1349 - val_loss: 2.0989 - val_acc: 0.1646\n",
      "Epoch 17/150\n",
      "50000/50000 [==============================] - 139s - loss: 1.9050 - acc: 0.2710 - val_loss: 1.6267 - val_acc: 0.3959\n",
      "Epoch 18/150\n",
      "50000/50000 [==============================] - 140s - loss: 1.5414 - acc: 0.4348 - val_loss: 1.4535 - val_acc: 0.4828\n",
      "Epoch 19/150\n",
      "50000/50000 [==============================] - 139s - loss: 1.3845 - acc: 0.4999 - val_loss: 1.3420 - val_acc: 0.5067\n",
      "Epoch 20/150\n",
      "50000/50000 [==============================] - 139s - loss: 1.2567 - acc: 0.5499 - val_loss: 1.2062 - val_acc: 0.5721\n",
      "Epoch 21/150\n",
      "50000/50000 [==============================] - 139s - loss: 1.1701 - acc: 0.5847 - val_loss: 1.1222 - val_acc: 0.6041\n",
      "Epoch 22/150\n",
      "50000/50000 [==============================] - 140s - loss: 1.1065 - acc: 0.6099 - val_loss: 1.0665 - val_acc: 0.6142\n",
      "Epoch 23/150\n",
      "50000/50000 [==============================] - 140s - loss: 1.0556 - acc: 0.6290 - val_loss: 1.0579 - val_acc: 0.6234\n",
      "Epoch 24/150\n",
      "50000/50000 [==============================] - 140s - loss: 1.0061 - acc: 0.6473 - val_loss: 0.9998 - val_acc: 0.6482\n",
      "Epoch 25/150\n",
      "50000/50000 [==============================] - 140s - loss: 0.9739 - acc: 0.6567 - val_loss: 0.9710 - val_acc: 0.6579\n",
      "Epoch 26/150\n",
      "50000/50000 [==============================] - 139s - loss: 0.9525 - acc: 0.6679 - val_loss: 0.9864 - val_acc: 0.6532\n",
      "Epoch 27/150\n",
      "50000/50000 [==============================] - 141s - loss: 0.9267 - acc: 0.6749 - val_loss: 1.0468 - val_acc: 0.6427\n",
      "Epoch 28/150\n",
      "50000/50000 [==============================] - 141s - loss: 0.9039 - acc: 0.6837 - val_loss: 0.9687 - val_acc: 0.6669\n",
      "Epoch 29/150\n",
      "50000/50000 [==============================] - 140s - loss: 0.8859 - acc: 0.6920 - val_loss: 0.9538 - val_acc: 0.6687\n",
      "Epoch 30/150\n",
      "50000/50000 [==============================] - 139s - loss: 0.8704 - acc: 0.6990 - val_loss: 1.0666 - val_acc: 0.6401\n",
      "Epoch 31/150\n",
      "50000/50000 [==============================] - 139s - loss: 0.8573 - acc: 0.7007 - val_loss: 0.9437 - val_acc: 0.6744\n",
      "Epoch 32/150\n",
      "50000/50000 [==============================] - 139s - loss: 0.8380 - acc: 0.7089 - val_loss: 0.9488 - val_acc: 0.6734\n",
      "Epoch 33/150\n",
      "50000/50000 [==============================] - 139s - loss: 0.8297 - acc: 0.7131 - val_loss: 0.9168 - val_acc: 0.6833\n",
      "Epoch 34/150\n",
      "50000/50000 [==============================] - 128s - loss: 0.8134 - acc: 0.7158 - val_loss: 0.9377 - val_acc: 0.6780\n",
      "Epoch 35/150\n",
      "50000/50000 [==============================] - 130s - loss: 0.8062 - acc: 0.7222 - val_loss: 0.8933 - val_acc: 0.6939\n",
      "Epoch 36/150\n",
      "50000/50000 [==============================] - 128s - loss: 0.7956 - acc: 0.7242 - val_loss: 0.9000 - val_acc: 0.6866\n",
      "Epoch 37/150\n",
      "50000/50000 [==============================] - 132s - loss: 0.7929 - acc: 0.7231 - val_loss: 0.9214 - val_acc: 0.6842\n",
      "Epoch 38/150\n",
      "50000/50000 [==============================] - 133s - loss: 0.7915 - acc: 0.7247 - val_loss: 0.9598 - val_acc: 0.6715\n",
      "Epoch 39/150\n",
      "50000/50000 [==============================] - 132s - loss: 0.7804 - acc: 0.7275 - val_loss: 0.9274 - val_acc: 0.6810\n",
      "Epoch 40/150\n",
      "50000/50000 [==============================] - 131s - loss: 0.7677 - acc: 0.7353 - val_loss: 0.9021 - val_acc: 0.6911\n",
      "Epoch 41/150\n",
      "50000/50000 [==============================] - 129s - loss: 0.7645 - acc: 0.7369 - val_loss: 0.9050 - val_acc: 0.6927\n",
      "Epoch 42/150\n",
      "50000/50000 [==============================] - 133s - loss: 0.7605 - acc: 0.7362 - val_loss: 0.8904 - val_acc: 0.6953\n",
      "Epoch 43/150\n",
      "50000/50000 [==============================] - 137s - loss: 0.7598 - acc: 0.7366 - val_loss: 0.9060 - val_acc: 0.6876\n",
      "Epoch 44/150\n",
      "50000/50000 [==============================] - 142s - loss: 0.7569 - acc: 0.7389 - val_loss: 0.9032 - val_acc: 0.6942\n",
      "Epoch 45/150\n",
      "50000/50000 [==============================] - 145s - loss: 0.7612 - acc: 0.7365 - val_loss: 0.9462 - val_acc: 0.6816\n",
      "Epoch 46/150\n",
      "50000/50000 [==============================] - 147s - loss: 0.7459 - acc: 0.7426 - val_loss: 0.8742 - val_acc: 0.7023\n",
      "Epoch 47/150\n",
      "50000/50000 [==============================] - 143s - loss: 0.7501 - acc: 0.7416 - val_loss: 0.8958 - val_acc: 0.6943\n",
      "Epoch 48/150\n",
      "50000/50000 [==============================] - 140s - loss: 0.7457 - acc: 0.7428 - val_loss: 0.9171 - val_acc: 0.6881\n",
      "Epoch 49/150\n",
      "50000/50000 [==============================] - 138s - loss: 0.7342 - acc: 0.7470 - val_loss: 0.8879 - val_acc: 0.6950\n",
      "Epoch 50/150\n",
      "50000/50000 [==============================] - 133s - loss: 0.7311 - acc: 0.7464 - val_loss: 0.8938 - val_acc: 0.7032\n",
      "Epoch 51/150\n",
      "50000/50000 [==============================] - 136s - loss: 0.7425 - acc: 0.7441 - val_loss: 0.8845 - val_acc: 0.7043\n",
      "Epoch 52/150\n",
      "50000/50000 [==============================] - 133s - loss: 0.7294 - acc: 0.7466 - val_loss: 0.9380 - val_acc: 0.6836\n",
      "Epoch 53/150\n",
      "50000/50000 [==============================] - 133s - loss: 0.7350 - acc: 0.7447 - val_loss: 0.8639 - val_acc: 0.7071\n",
      "Epoch 54/150\n",
      "50000/50000 [==============================] - 135s - loss: 0.7220 - acc: 0.7501 - val_loss: 0.8633 - val_acc: 0.7060\n",
      "Epoch 55/150\n",
      "50000/50000 [==============================] - 134s - loss: 0.7388 - acc: 0.7440 - val_loss: 0.8860 - val_acc: 0.7011\n",
      "Epoch 56/150\n",
      "50000/50000 [==============================] - 137s - loss: 0.7254 - acc: 0.7489 - val_loss: 0.9478 - val_acc: 0.6813\n",
      "Epoch 57/150\n",
      "50000/50000 [==============================] - 136s - loss: 0.7225 - acc: 0.7490 - val_loss: 0.8851 - val_acc: 0.6993\n",
      "Epoch 58/150\n",
      "50000/50000 [==============================] - 135s - loss: 0.7140 - acc: 0.7525 - val_loss: 0.8933 - val_acc: 0.6979\n",
      "Epoch 59/150\n",
      "50000/50000 [==============================] - 133s - loss: 0.7142 - acc: 0.7507 - val_loss: 0.9457 - val_acc: 0.6799\n",
      "Epoch 60/150\n",
      "50000/50000 [==============================] - 135s - loss: 0.7202 - acc: 0.7517 - val_loss: 0.8905 - val_acc: 0.7024\n",
      "Epoch 61/150\n",
      "50000/50000 [==============================] - 136s - loss: 0.7133 - acc: 0.7527 - val_loss: 0.9047 - val_acc: 0.7002\n",
      "Epoch 62/150\n",
      "50000/50000 [==============================] - 139s - loss: 0.7105 - acc: 0.7525 - val_loss: 0.8819 - val_acc: 0.7039\n",
      "Epoch 63/150\n",
      "50000/50000 [==============================] - 138s - loss: 0.7218 - acc: 0.7502 - val_loss: 0.9225 - val_acc: 0.6926\n",
      "Epoch 64/150\n",
      "50000/50000 [==============================] - 146s - loss: 0.7082 - acc: 0.7563 - val_loss: 0.8864 - val_acc: 0.7019\n",
      "Epoch 65/150\n",
      "50000/50000 [==============================] - 148s - loss: 0.6976 - acc: 0.7608 - val_loss: 0.9405 - val_acc: 0.6857\n",
      "Epoch 66/150\n",
      "50000/50000 [==============================] - 157s - loss: 0.7135 - acc: 0.7536 - val_loss: 0.9053 - val_acc: 0.6962\n",
      "Epoch 67/150\n",
      "50000/50000 [==============================] - 141s - loss: 0.7111 - acc: 0.7541 - val_loss: 0.9206 - val_acc: 0.6903\n",
      "Epoch 68/150\n",
      "50000/50000 [==============================] - 146s - loss: 0.7160 - acc: 0.7521 - val_loss: 0.8845 - val_acc: 0.6970\n",
      "Epoch 69/150\n",
      "50000/50000 [==============================] - 145s - loss: 0.7044 - acc: 0.7577 - val_loss: 0.8779 - val_acc: 0.7058\n",
      "Epoch 70/150\n",
      "50000/50000 [==============================] - 142s - loss: 0.7087 - acc: 0.7545 - val_loss: 0.9485 - val_acc: 0.6894\n",
      "Epoch 71/150\n",
      "50000/50000 [==============================] - 137s - loss: 0.7158 - acc: 0.7534 - val_loss: 0.9036 - val_acc: 0.6921\n",
      "Epoch 72/150\n",
      "50000/50000 [==============================] - 145s - loss: 0.7064 - acc: 0.7562 - val_loss: 0.8802 - val_acc: 0.7020\n",
      "Epoch 73/150\n",
      "50000/50000 [==============================] - 151s - loss: 0.7057 - acc: 0.7571 - val_loss: 0.9310 - val_acc: 0.6888\n",
      "Epoch 74/150\n",
      "50000/50000 [==============================] - 146s - loss: 0.7164 - acc: 0.7523 - val_loss: 0.9057 - val_acc: 0.6986\n",
      "Epoch 75/150\n",
      "50000/50000 [==============================] - 131s - loss: 0.7212 - acc: 0.7506 - val_loss: 0.9005 - val_acc: 0.7030\n",
      "Epoch 76/150\n",
      "50000/50000 [==============================] - 131s - loss: 0.7093 - acc: 0.7567 - val_loss: 0.9003 - val_acc: 0.6978\n",
      "Epoch 77/150\n",
      "50000/50000 [==============================] - 132s - loss: 0.7163 - acc: 0.7529 - val_loss: 0.8851 - val_acc: 0.6996\n",
      "Epoch 78/150\n",
      "50000/50000 [==============================] - 131s - loss: 0.7195 - acc: 0.7506 - val_loss: 0.8625 - val_acc: 0.7108\n",
      "Epoch 79/150\n",
      "50000/50000 [==============================] - 131s - loss: 0.7148 - acc: 0.7531 - val_loss: 0.8712 - val_acc: 0.7112\n",
      "Epoch 80/150\n",
      "50000/50000 [==============================] - 132s - loss: 0.7114 - acc: 0.7552 - val_loss: 0.8749 - val_acc: 0.7023\n",
      "Epoch 81/150\n",
      "50000/50000 [==============================] - 132s - loss: 0.7162 - acc: 0.7531 - val_loss: 0.9257 - val_acc: 0.6917\n",
      "Epoch 82/150\n",
      "50000/50000 [==============================] - 135s - loss: 0.7003 - acc: 0.7581 - val_loss: 0.9006 - val_acc: 0.6966\n",
      "Epoch 83/150\n",
      "50000/50000 [==============================] - 133s - loss: 0.6982 - acc: 0.7590 - val_loss: 0.8859 - val_acc: 0.6967\n",
      "Epoch 84/150\n",
      "50000/50000 [==============================] - 136s - loss: 0.7232 - acc: 0.7512 - val_loss: 0.8936 - val_acc: 0.7036\n",
      "Epoch 85/150\n",
      "50000/50000 [==============================] - 132s - loss: 0.7118 - acc: 0.7542 - val_loss: 0.9083 - val_acc: 0.6998\n",
      "Epoch 86/150\n",
      "50000/50000 [==============================] - 136s - loss: 0.7126 - acc: 0.7537 - val_loss: 0.9020 - val_acc: 0.6950\n",
      "Epoch 87/150\n",
      "50000/50000 [==============================] - 134s - loss: 0.7251 - acc: 0.7478 - val_loss: 0.8701 - val_acc: 0.7105\n",
      "Epoch 88/150\n",
      "50000/50000 [==============================] - 135s - loss: 0.7177 - acc: 0.7511 - val_loss: 0.8754 - val_acc: 0.7053\n",
      "Epoch 89/150\n",
      "50000/50000 [==============================] - 135s - loss: 0.7252 - acc: 0.7491 - val_loss: 0.9138 - val_acc: 0.6944\n",
      "Epoch 90/150\n",
      "50000/50000 [==============================] - 134s - loss: 0.6974 - acc: 0.7591 - val_loss: 0.8684 - val_acc: 0.7071\n",
      "Epoch 91/150\n",
      "50000/50000 [==============================] - 133s - loss: 0.7143 - acc: 0.7514 - val_loss: 0.9023 - val_acc: 0.6957\n",
      "Epoch 92/150\n",
      "50000/50000 [==============================] - 133s - loss: 0.7364 - acc: 0.7456 - val_loss: 0.8924 - val_acc: 0.7001\n",
      "Epoch 93/150\n",
      "50000/50000 [==============================] - 133s - loss: 0.7048 - acc: 0.7562 - val_loss: 0.8937 - val_acc: 0.6989\n",
      "Epoch 94/150\n",
      "50000/50000 [==============================] - 132s - loss: 0.7175 - acc: 0.7518 - val_loss: 0.9437 - val_acc: 0.6838\n",
      "Epoch 95/150\n",
      "50000/50000 [==============================] - 133s - loss: 0.7299 - acc: 0.7474 - val_loss: 0.8823 - val_acc: 0.7017\n",
      "Epoch 96/150\n",
      "50000/50000 [==============================] - 133s - loss: 0.7172 - acc: 0.7495 - val_loss: 0.8855 - val_acc: 0.7040\n",
      "Epoch 97/150\n",
      "50000/50000 [==============================] - 133s - loss: 0.7125 - acc: 0.7535 - val_loss: 0.9022 - val_acc: 0.6961\n",
      "Epoch 98/150\n",
      "50000/50000 [==============================] - 133s - loss: 0.7086 - acc: 0.7549 - val_loss: 0.9058 - val_acc: 0.6935\n",
      "Epoch 99/150\n",
      "50000/50000 [==============================] - 133s - loss: 0.7211 - acc: 0.7512 - val_loss: 0.8862 - val_acc: 0.7002\n",
      "Epoch 100/150\n",
      "50000/50000 [==============================] - 133s - loss: 0.7127 - acc: 0.7541 - val_loss: 0.9049 - val_acc: 0.6953\n",
      "Epoch 101/150\n",
      "50000/50000 [==============================] - 133s - loss: 0.7411 - acc: 0.7439 - val_loss: 0.8801 - val_acc: 0.7037\n",
      "Epoch 102/150\n",
      "50000/50000 [==============================] - 133s - loss: 0.6981 - acc: 0.7565 - val_loss: 0.8924 - val_acc: 0.7002\n",
      "Epoch 103/150\n",
      "50000/50000 [==============================] - 134s - loss: 0.7122 - acc: 0.7542 - val_loss: 0.8850 - val_acc: 0.7019\n",
      "Epoch 104/150\n",
      "50000/50000 [==============================] - 134s - loss: 0.6991 - acc: 0.7579 - val_loss: 0.8801 - val_acc: 0.7074\n",
      "Epoch 105/150\n",
      "50000/50000 [==============================] - 134s - loss: 0.7205 - acc: 0.7506 - val_loss: 0.8834 - val_acc: 0.7024\n",
      "Epoch 106/150\n",
      "50000/50000 [==============================] - 132s - loss: 0.6934 - acc: 0.7598 - val_loss: 0.9035 - val_acc: 0.7021\n",
      "Epoch 107/150\n",
      "50000/50000 [==============================] - 133s - loss: 0.7108 - acc: 0.7538 - val_loss: 0.9081 - val_acc: 0.7017\n",
      "Epoch 108/150\n",
      "50000/50000 [==============================] - 133s - loss: 0.7225 - acc: 0.7502 - val_loss: 0.9004 - val_acc: 0.6994\n",
      "Epoch 109/150\n",
      "50000/50000 [==============================] - 133s - loss: 0.7126 - acc: 0.7519 - val_loss: 0.8724 - val_acc: 0.7079\n",
      "Epoch 110/150\n",
      "50000/50000 [==============================] - 133s - loss: 0.7248 - acc: 0.7505 - val_loss: 0.8878 - val_acc: 0.7039\n",
      "Epoch 111/150\n",
      "50000/50000 [==============================] - 133s - loss: 0.7259 - acc: 0.7500 - val_loss: 0.8935 - val_acc: 0.6995\n",
      "Epoch 112/150\n",
      "50000/50000 [==============================] - 135s - loss: 0.7137 - acc: 0.7547 - val_loss: 0.8701 - val_acc: 0.7054\n",
      "Epoch 113/150\n",
      "50000/50000 [==============================] - 134s - loss: 0.7192 - acc: 0.7520 - val_loss: 0.9015 - val_acc: 0.6920\n",
      "Epoch 114/150\n",
      "50000/50000 [==============================] - 133s - loss: 0.7184 - acc: 0.7518 - val_loss: 0.9642 - val_acc: 0.6736\n",
      "Epoch 115/150\n",
      "50000/50000 [==============================] - 133s - loss: 0.7426 - acc: 0.7439 - val_loss: 0.8796 - val_acc: 0.7023\n",
      "Epoch 116/150\n",
      "50000/50000 [==============================] - 133s - loss: 0.7187 - acc: 0.7503 - val_loss: 0.8986 - val_acc: 0.6982\n",
      "Epoch 117/150\n",
      "50000/50000 [==============================] - 133s - loss: 0.7292 - acc: 0.7500 - val_loss: 0.8815 - val_acc: 0.7045\n",
      "Epoch 118/150\n",
      "50000/50000 [==============================] - 133s - loss: 0.7215 - acc: 0.7508 - val_loss: 0.9246 - val_acc: 0.6878\n",
      "Epoch 119/150\n",
      "50000/50000 [==============================] - 133s - loss: 0.7328 - acc: 0.7448 - val_loss: 0.8950 - val_acc: 0.7021\n",
      "Epoch 120/150\n",
      "50000/50000 [==============================] - 133s - loss: 0.7167 - acc: 0.7528 - val_loss: 0.9024 - val_acc: 0.6960\n",
      "Epoch 121/150\n",
      "50000/50000 [==============================] - 133s - loss: 0.7298 - acc: 0.7488 - val_loss: 0.9796 - val_acc: 0.6699\n",
      "Epoch 122/150\n",
      "50000/50000 [==============================] - 133s - loss: 0.7160 - acc: 0.7530 - val_loss: 0.8822 - val_acc: 0.7081\n",
      "Epoch 123/150\n",
      "50000/50000 [==============================] - 133s - loss: 0.7129 - acc: 0.7540 - val_loss: 0.8768 - val_acc: 0.7090\n",
      "Epoch 124/150\n",
      "50000/50000 [==============================] - 133s - loss: 0.7122 - acc: 0.7535 - val_loss: 0.9037 - val_acc: 0.6992\n",
      "Epoch 125/150\n",
      "50000/50000 [==============================] - 133s - loss: 0.7195 - acc: 0.7495 - val_loss: 0.9356 - val_acc: 0.6811\n",
      "Epoch 126/150\n",
      "50000/50000 [==============================] - 133s - loss: 0.7164 - acc: 0.7488 - val_loss: 0.8897 - val_acc: 0.6979\n",
      "Epoch 127/150\n",
      "50000/50000 [==============================] - 133s - loss: 0.7548 - acc: 0.7402 - val_loss: 0.8884 - val_acc: 0.6988\n",
      "Epoch 128/150\n",
      "50000/50000 [==============================] - 133s - loss: 0.7572 - acc: 0.7355 - val_loss: 0.9128 - val_acc: 0.6932\n",
      "Epoch 129/150\n",
      "50000/50000 [==============================] - 133s - loss: 0.7493 - acc: 0.7398 - val_loss: 0.9309 - val_acc: 0.6793\n",
      "Epoch 130/150\n",
      "50000/50000 [==============================] - 133s - loss: 0.7652 - acc: 0.7352 - val_loss: 0.9313 - val_acc: 0.6819\n",
      "Epoch 131/150\n",
      "50000/50000 [==============================] - 133s - loss: 0.7537 - acc: 0.7379 - val_loss: 0.9791 - val_acc: 0.6726\n",
      "Epoch 132/150\n",
      "50000/50000 [==============================] - 133s - loss: 0.7377 - acc: 0.7428 - val_loss: 0.9006 - val_acc: 0.6987\n",
      "Epoch 133/150\n",
      "50000/50000 [==============================] - 133s - loss: 0.7301 - acc: 0.7463 - val_loss: 0.9176 - val_acc: 0.6917\n",
      "Epoch 134/150\n",
      "50000/50000 [==============================] - 133s - loss: 0.7214 - acc: 0.7485 - val_loss: 0.9084 - val_acc: 0.6934\n",
      "Epoch 135/150\n",
      "50000/50000 [==============================] - 133s - loss: 0.7298 - acc: 0.7484 - val_loss: 0.8720 - val_acc: 0.7080\n",
      "Epoch 136/150\n",
      "50000/50000 [==============================] - 133s - loss: 0.7292 - acc: 0.7471 - val_loss: 0.9235 - val_acc: 0.6900\n",
      "Epoch 137/150\n",
      "50000/50000 [==============================] - 133s - loss: 0.7477 - acc: 0.7395 - val_loss: 0.8957 - val_acc: 0.6968\n",
      "Epoch 138/150\n",
      "50000/50000 [==============================] - 133s - loss: 0.7274 - acc: 0.7476 - val_loss: 0.9290 - val_acc: 0.6869\n",
      "Epoch 139/150\n",
      "50000/50000 [==============================] - 133s - loss: 0.7481 - acc: 0.7411 - val_loss: 0.9166 - val_acc: 0.6881\n",
      "Epoch 140/150\n",
      "50000/50000 [==============================] - 133s - loss: 0.7431 - acc: 0.7435 - val_loss: 0.9189 - val_acc: 0.6927\n",
      "Epoch 141/150\n",
      "50000/50000 [==============================] - 133s - loss: 0.7667 - acc: 0.7341 - val_loss: 0.8958 - val_acc: 0.6961\n",
      "Epoch 142/150\n",
      "50000/50000 [==============================] - 133s - loss: 0.7798 - acc: 0.7295 - val_loss: 0.9074 - val_acc: 0.6970\n",
      "Epoch 143/150\n",
      "50000/50000 [==============================] - 133s - loss: 0.7483 - acc: 0.7427 - val_loss: 0.8691 - val_acc: 0.7083\n",
      "Epoch 144/150\n",
      "50000/50000 [==============================] - 133s - loss: 0.7437 - acc: 0.7427 - val_loss: 0.9459 - val_acc: 0.6807\n",
      "Epoch 145/150\n",
      "50000/50000 [==============================] - 133s - loss: 0.7397 - acc: 0.7472 - val_loss: 0.9548 - val_acc: 0.6793\n",
      "Epoch 146/150\n",
      "50000/50000 [==============================] - 133s - loss: 0.7939 - acc: 0.7254 - val_loss: 0.9210 - val_acc: 0.6858\n",
      "Epoch 147/150\n",
      "50000/50000 [==============================] - 133s - loss: 0.7603 - acc: 0.7395 - val_loss: 0.9268 - val_acc: 0.6883\n",
      "Epoch 148/150\n",
      "50000/50000 [==============================] - 133s - loss: 0.7418 - acc: 0.7420 - val_loss: 0.9008 - val_acc: 0.7006\n",
      "Epoch 149/150\n",
      "50000/50000 [==============================] - 133s - loss: 0.7638 - acc: 0.7366 - val_loss: 0.9143 - val_acc: 0.6962\n",
      "Epoch 150/150\n",
      "50000/50000 [==============================] - 133s - loss: 0.7513 - acc: 0.7393 - val_loss: 0.9180 - val_acc: 0.6896\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ec4d9b0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%%capture\n",
    "model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch,verbose=1, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.918008049488\n",
      "Test accuracy: 0.6896\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from ipywidgets import interact, interactive, fixed\n",
    "from ipywidgets import widgets\n",
    "\n",
    "def f(x):\n",
    "    \n",
    "    plt.imshow(Tr_X[x].reshape(img_rows,img_rows,3)) # color\n",
    "    #plt.imshow(X_train[x].reshape(img_rows,img_rows)) # gray\n",
    "    print (loaded_model.predict(X_train[x].reshape(1,img_channels,img_rows,img_rows)) )\n",
    "    print (loaded_model.predict_classes(X_train[x].reshape(1,img_channels,img_rows,img_rows)) ,'--><--', np.argmax(Y_train[x]) )\n",
    "\n",
    "interact(f,x = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
