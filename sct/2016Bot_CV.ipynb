{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2016 Bot \n",
    "\n",
    "### Overview\n",
    "- Introduction \n",
    "- Data ETL\n",
    "- Data Augmentation \n",
    "- Networks Architecture \n",
    "- Training \n",
    "- Model Averaging \n",
    "- Conclusion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os, sys, glob\n",
    "import numpy as np\n",
    "import cv2\n",
    "from skimage.io import imread\n",
    "\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data Augmentation \n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# model build \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import SGD\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from keras.models import model_from_json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Conf:\n",
    "    def __init__(self, confPath):\n",
    "        # load and store the configuration and update the object's dictionary\n",
    "        conf = json.loads(open(confPath).read())\n",
    "        self.__dict__.update(conf)\n",
    "\n",
    "    def __getitem__(self, k):\n",
    "        # return the value associated with the supplied key\n",
    "        return self.__dict__.get(k, None)\n",
    "    \n",
    "    \n",
    "def auto_resized(img,size):\n",
    "    '''size = (width,height)'''\n",
    "    size = tuple(size)\n",
    "    resize_img = cv2.resize(img, size, interpolation=cv2.INTER_LINEAR)\n",
    "    return resize_img\n",
    "\n",
    "def TrainFilePath(folderPath, constrain=None, **kargs):\n",
    "    '''\n",
    "    (1) Output filepath and calssName\n",
    "    (2) folderPath \n",
    "          --label_1\n",
    "           -- xxx.jpg\n",
    "    '''\n",
    "    assert folderPath[-1]!='/'\n",
    "    if constrain is None:\n",
    "        constrain = ('avi', 'mp4','png','jpg') \n",
    "    for (rootDir, dirNames, fileNames) in os.walk(folderPath):\n",
    "        for fileName in fileNames:\n",
    "            if fileName.split('.')[-1] in constrain:\n",
    "                yield (os.path.join(rootDir, fileName)) \n",
    "                \n",
    "#img_channels = 3\n",
    "def genTrX(filePath, resolution, img_channels=3):\n",
    "    assert type(resolution) == tuple\n",
    "    img = auto_resized(imread(filePath),resolution)  #conf['sliding_size']\n",
    "    if img_channels==1:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    elif img_channels==3:\n",
    "        img = img[:,:,:3]\n",
    "    return img\n",
    "                \n",
    "def load_training(folderList, img_rows, img_cols, img_channels):\n",
    "    TrY = []\n",
    "    TrX = []\n",
    "    TrY_template = np.eye(len(folderList))\n",
    "    for eyeId, folderPath in enumerate(folderList):\n",
    "        for imgPath in TrainFilePath(folderPath) :\n",
    "            TrY.append(TrY_template[eyeId])\n",
    "            TrX.append(genTrX(imgPath, (img_rows,img_cols), img_channels))\n",
    "    print (len(TrX))\n",
    "    return TrX, TrY\n",
    "\n",
    "def create_folderList(rootDir):\n",
    "    result=[]\n",
    "    for a in os.listdir(rootDir):\n",
    "        a = os.path.join(rootDir, a)\n",
    "        if os.path.isdir(a):\n",
    "            result.append(a) \n",
    "    return result\n",
    "\n",
    "\n",
    "def reshapeShuffle(TrX, TrY, img_rows, img_cols, img_channels):\n",
    "    trainX = np.asarray(TrX, dtype = np.uint8)\n",
    "    trainX = trainX.reshape(trainX.shape[0], img_channels, img_rows, img_cols)\n",
    "    trainX = trainX.astype('float32')\n",
    "    trainY = np.asarray(TrY, dtype = np.float32)\n",
    "    # shuffle\n",
    "    trainX , trainY = shuffle(trainX,trainY)\n",
    "    print ('Train_X : ',trainX.shape,'Train_Y' ,trainY.shape)\n",
    "    return trainX , trainY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116481\n"
     ]
    }
   ],
   "source": [
    "ROOT_Dir = 'D:\\\\2016bot_cv'\n",
    "\n",
    "img_rows= 280\n",
    "\n",
    "img_cols= 280\n",
    "\n",
    "img_channels=3\n",
    "\n",
    "folderList = create_folderList(ROOT_Dir)\n",
    "\n",
    "Train_X, Train_Y = load_training(folderList, img_rows, img_cols, img_channels)\n",
    "\n",
    "\n",
    "\n",
    "#TrainFilePath('D:\\2015')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-87-ac1e135be8e0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_X\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mtrain_Y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreshapeShuffle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTrain_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTrain_Y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_rows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_cols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_channels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimg_channels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-44-5a2c35620161>\u001b[0m in \u001b[0;36mreshapeShuffle\u001b[1;34m(TrX, TrY, img_rows, img_cols, img_channels)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mreshapeShuffle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTrX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTrY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_rows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_cols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_channels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m     \u001b[0mtrainX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTrX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[0mtrainX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_channels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_rows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_cols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[0mtrainX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'float32'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\kentc\\Anaconda2\\lib\\site-packages\\numpy\\core\\numeric.pyc\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m    480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m     \"\"\"\n\u001b[1;32m--> 482\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    483\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_X , train_Y = reshapeShuffle(Train_X, Train_Y, img_rows, img_cols, img_channels=img_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gen_Img = ImageDataGenerator(featurewise_center=False,\n",
    "    samplewise_center=True,\n",
    "    featurewise_std_normalization=False,\n",
    "    samplewise_std_normalization=False,\n",
    "    zca_whitening=True,\n",
    "    rotation_range=180.,\n",
    "    width_shift_range=.2,\n",
    "    height_shift_range=.2,\n",
    "    shear_range=.2,\n",
    "    zoom_range=[0.5, 1.5],\n",
    "    channel_shift_range=0.,\n",
    "    fill_mode='nearest',\n",
    "    cval=0.,\n",
    "    horizontal_flip=False,\n",
    "    vertical_flip=False,\n",
    "    rescale=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen_Img.fit(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class ConvNetFactory:\n",
    "\tdef __init__(self):\n",
    "\t\tpass\n",
    "\n",
    "\t@staticmethod\n",
    "\tdef build(name, *args, **kargs):\n",
    "\t\t# define the network (i.e., string => function) mappings\n",
    "\t\tmappings = {\n",
    "\t\t\t\"shallownet\": ConvNetFactory.ShallowNet,\n",
    "\t\t\t\"lenet\": ConvNetFactory.LeNet,\n",
    "\t\t\t\"karpathynet\": ConvNetFactory.KarpathyNet,\n",
    "\t\t\t\"minivggnet\": ConvNetFactory.MiniVGGNet}\n",
    "\n",
    "\t\t# grab the builder function from the mappings dictionary\n",
    "\t\tbuilder = mappings.get(name, None)\n",
    "\n",
    "\t\t# if the builder is None, then there is not a function that can be used\n",
    "\t\t# to build to the network, so return None\n",
    "\t\tif builder is None:\n",
    "\t\t\treturn None\n",
    "\n",
    "\t\t# otherwise, build the network architecture\n",
    "\t\treturn builder(*args, **kargs)\n",
    "\n",
    "\t@staticmethod\n",
    "\tdef ShallowNet(numChannels, imgRows, imgCols, numClasses, **kwargs):\n",
    "\t\t# initialzie the model\n",
    "\t\tmodel = Sequential()\n",
    "\n",
    "\t\t# define the first (and only) CONV => RELU layer\n",
    "\t\tmodel.add(Convolution2D(32, 3, 3, border_mode=\"same\",\n",
    "\t\t\tinput_shape=(numChannels, imgRows, imgCols)))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\n",
    "\t\t# add a FC layer followed by the soft-max classifier\n",
    "\t\tmodel.add(Flatten())\n",
    "\t\tmodel.add(Dense(numClasses))\n",
    "\t\tmodel.add(Activation(\"softmax\"))\n",
    "\n",
    "\t\t# return the network architecture\n",
    "\t\treturn model\n",
    "\n",
    "\t@staticmethod\n",
    "\tdef LeNet(numChannels, imgRows, imgCols, numClasses, activation=\"tanh\", **kwargs):\n",
    "\t\t# initialize the model\n",
    "\t\tmodel = Sequential()\n",
    "\n",
    "\t\t# define the first set of CONV => ACTIVATION => POOL layers\n",
    "\t\tmodel.add(Convolution2D(20, 5, 5, border_mode=\"same\",\n",
    "\t\t\tinput_shape=(numChannels, imgRows, imgCols)))\n",
    "\t\tmodel.add(Activation(activation))\n",
    "\t\tmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "\t\t# define the second set of CONV => ACTIVATION => POOL layers\n",
    "\t\tmodel.add(Convolution2D(50, 5, 5, border_mode=\"same\"))\n",
    "\t\tmodel.add(Activation(activation))\n",
    "\t\tmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "\t\t# define the first FC => ACTIVATION layers\n",
    "\t\tmodel.add(Flatten())\n",
    "\t\tmodel.add(Dense(500))\n",
    "\t\tmodel.add(Activation(activation))\n",
    "\n",
    "\t\t# define the second FC layer\n",
    "\t\tmodel.add(Dense(numClasses))\n",
    "\n",
    "\t\t# lastly, define the soft-max classifier\n",
    "\t\tmodel.add(Activation(\"softmax\"))\n",
    "\n",
    "\t\t# return the network architecture\n",
    "\t\treturn model\n",
    "\n",
    "\t@staticmethod\n",
    "\tdef KarpathyNet():\n",
    "\t\t# initialize the model\n",
    "\t\tmodel = Sequential()\n",
    "\n",
    "\t\t# define the first set of CONV => RELU => POOL layers\n",
    "\t\tmodel.add(Convolution2D(16, 5, 5, border_mode=\"same\",\n",
    "\t\t\tinput_shape=(numChannels, imgRows, imgCols)))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\tmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "\t\t# check to see if dropout should be applied to reduce overfitting\n",
    "\t\tif dropout:\n",
    "\t\t\tmodel.add(Dropout(0.25))\n",
    "\n",
    "\t\t# define the second set of CONV => RELU => POOL layers\n",
    "\t\tmodel.add(Convolution2D(20, 5, 5, border_mode=\"same\"))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\tmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "\t\t# check to see if dropout should be applied to reduce overfitting\n",
    "\t\tif dropout:\n",
    "\t\t\tmodel.add(Dropout(0.25))\n",
    "\n",
    "\t\t# define the third set of CONV => RELU => POOL layers\n",
    "\t\tmodel.add(Convolution2D(20, 5, 5, border_mode=\"same\"))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\tmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "\t\t# check to see if dropout should be applied to reduce overfitting\n",
    "\t\tif dropout:\n",
    "\t\t\tmodel.add(Dropout(0.5))\n",
    "\n",
    "\t\t# define the soft-max classifier\n",
    "\t\tmodel.add(Flatten())\n",
    "\t\tmodel.add(Dense(numClasses))\n",
    "\t\tmodel.add(Activation(\"softmax\"))\n",
    "\n",
    "\t\t# return the network architecture\n",
    "\t\treturn model\n",
    "\n",
    "\t@staticmethod\n",
    "\tdef MiniVGGNet():\n",
    "\t\t# initialize the model\n",
    "\t\tmodel = Sequential()\n",
    "\n",
    "\t\t# define the first set of CONV => RELU => CONV => RELU => POOL layers\n",
    "\t\tmodel.add(Convolution2D(32, 3, 3, border_mode=\"same\",\n",
    "\t\t\tinput_shape=(numChannels, imgRows, imgCols)))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\tmodel.add(Convolution2D(32, 3, 3))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\t\t# check to see if dropout should be applied to reduce overfitting\n",
    "\t\tif dropout:\n",
    "\t\t\tmodel.add(Dropout(0.25))\n",
    "\n",
    "\t\t# define the second set of CONV => RELU => CONV => RELU => POOL layers\n",
    "\t\tmodel.add(Convolution2D(64, 3, 3, border_mode=\"same\"))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\tmodel.add(Convolution2D(64, 3, 3))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\t\t# check to see if dropout should be applied to reduce overfitting\n",
    "\t\tif dropout:\n",
    "\t\t\tmodel.add(Dropout(0.25))\n",
    "\n",
    "\t\t# define the set of FC => RELU layers\n",
    "\t\tmodel.add(Flatten())\n",
    "\t\tmodel.add(Dense(512))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\n",
    "\t\t# check to see if dropout should be applied to reduce overfitting\n",
    "\t\tif dropout:\n",
    "\t\t\tmodel.add(Dropout(0.5))\n",
    "\n",
    "\t\t# define the soft-max classifier\n",
    "\t\tmodel.add(Dense(numClasses))\n",
    "\t\tmodel.add(Activation(\"softmax\"))\n",
    "\n",
    "\t\t# return the network architecture\n",
    "\t\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Flatten, Dense, Dropout\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "def VGG_19(weights_path=None):\n",
    "    model = Sequential()\n",
    "    model.add(ZeroPadding2D((1,1),input_shape=(3,280,280)))\n",
    "    model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(500, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(12, activation='softmax'))\n",
    "    \n",
    "    if weights_path:\n",
    "        model.load_weights(weights_path)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = VGG_19()\n",
    "#https://gist.github.com/baraldilorenzo/8d096f48a1be4a2d660d\n",
    "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(optimizer=sgd, loss='categorical_crossentropy')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "kf = KFold(len(train_Y), n_folds=3)\n",
    "for train, test in kf:\n",
    "    #print (train, test)\n",
    "    Tr_X = train_X[train]\n",
    "    Te_X = train_X[test]\n",
    "    Tr_Y = train_Y[train]\n",
    "    Te_Y = train_Y[test]\n",
    "    for X_batch, y_batch in gen_Img.flow(Tr_X , Tr_Y, batch_size=240):\n",
    "        model.fit(X_batch, y_batch, 240, nb_epoch=250,verbose=1, validation_data=(Te_X, Te_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "invalid index to scalar variable.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-77-710c35ee8e99>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTe_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTe_Y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Test score:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Test accuracy:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: invalid index to scalar variable."
     ]
    }
   ],
   "source": [
    "score = model.evaluate(Te_X, Te_Y, verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[ 0.12500012,  0.08750004,  0.09999988,  0.0791666 ,  0.09166677,\n",
      "         0.12499985,  0.07083347,  0.05833334,  0.06666683,  0.06249999,\n",
      "         0.04166663,  0.09166655]]), '--><--', 9)\n"
     ]
    }
   ],
   "source": [
    "print (model.predict(Te_X[1000].reshape(1,img_channels,img_rows,img_rows)) ,'--><--', np.argmax(Te_Y[1000]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.12500012,  0.08750004,  0.09999988,  0.0791666 ,  0.09166677,\n",
       "         0.12499985,  0.07083347,  0.05833334,  0.06666683,  0.06249999,\n",
       "         0.04166663,  0.09166655]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba(Te_X[3].reshape(1,img_channels,img_rows,img_rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Image Augmentation for Deep Learning With Keras\n",
    "by Jason Brownlee on June 29, 2016 in Deep Learning\n",
    "0\n",
    "0\n",
    "5\n",
    "42\n",
    "Data preparation is required when working with neural network and deep learning models. Increasingly data augmentation is also required on more complex object recognition tasks.\n",
    "\n",
    "In this post you will discover how to use data preparation and data augmentation with your image datasets when developing and evaluating deep learning models in Python with Keras.\n",
    "\n",
    "After reading this post, you will know:\n",
    "\n",
    "About the image augmentation API provide by Keras and how to use it with your models.\n",
    "How to perform feature standardization.\n",
    "How to perform ZCA whitening of your images.\n",
    "How to augment data with random rotations, shifts and flips.\n",
    "How to save augmented image data to disk.\n",
    "Let’s get started.\n",
    "\n",
    "Update: The examples in this post were updated for the latest Keras API. The datagen.next() function was removed.\n",
    "\n",
    "Keras Image Augmentation API\n",
    "\n",
    "Like the rest of Keras, the image augmentation API is simple and powerful.\n",
    "\n",
    "Keras provides the ImageDataGenerator class that defines the configuration for image data preparation and augmentation. This includes capabilities such as:\n",
    "\n",
    "Sample-wise standardization.\n",
    "Feature-wise standardization.\n",
    "ZCA whitening.\n",
    "Random rotation, shifts, shear and flips.\n",
    "Dimension reordering.\n",
    "Save augmented images to disk.\n",
    "An augmented image generator can be created as follows:\n",
    "\n",
    "\n",
    "datagen = ImageDataGenerator()\n",
    "1\n",
    "datagen = ImageDataGenerator()\n",
    "Rather than performing the operations on your entire image dataset in memory, the API is designed to be iterated by the deep learning model fitting process, creating augmented image data for you just-in-time. This reduces your memory overhead, but adds some additional time cost during model training.\n",
    "\n",
    "After you have created and configured your ImageDataGenerator, you must fit it on your data. This will calculate any statistics required to actually perform the transforms to your image data. You can do this by calling the fit() function on the data generator and pass it your training dataset.\n",
    "\n",
    "\n",
    "datagen.fit(train)\n",
    "1\n",
    "datagen.fit(train)\n",
    "The data generator itself is in fact an iterator, returning batches of image samples when requested. We can configure the batch size and prepare the data generator and get batches of images by calling the flow() function.\n",
    "\n",
    "\n",
    "X_batch, y_batch = datagen.flow(train, train, batch_size=32)\n",
    "1\n",
    "X_batch, y_batch = datagen.flow(train, train, batch_size=32)\n",
    "Finally we can make use of the data generator. Instead of calling the fit() function on our model, we must call the fit_generator() function and pass in the data generator and the desired length of an epoch as well as the total number of epochs on which to train.\n",
    "\n",
    "\n",
    "fit_generator(datagen, samples_per_epoch=len(train), nb_epoch=100)\n",
    "1\n",
    "fit_generator(datagen, samples_per_epoch=len(train), nb_epoch=100)\n",
    "You can learn more about the Keras image data generator API in the Keras documentation.\n",
    "\n",
    "Get Started in Deep Learning With Python\n",
    "\n",
    "Deep Learning with Python Mini-Course\n",
    "\n",
    "Deep Learning gets state-of-the-art results and Python hosts the most powerful tools. \n",
    "Get started now!\n",
    "\n",
    "PDF Download and Email Course.\n",
    "\n",
    "FREE 14-Day Mini-Course on \n",
    "Deep Learning With Python\n",
    "\n",
    "Download Your FREE Mini-Course\n",
    " \n",
    "\n",
    " Download your PDF containing all 14 lessons.\n",
    "\n",
    "Get your daily lesson via email with tips and tricks.\n",
    "\n",
    "Point of Comparison for Image Augmentation\n",
    "\n",
    "Now that you know how the image augmentation API in Keras works, let’s look at some examples.\n",
    "\n",
    "We will use the MNIST handwritten digit recognition task in these examples. To begin with, let’s take a look at the first 9 images in the training dataset.\n",
    "\n",
    "\n",
    "# Plot images\n",
    "from keras.datasets import mnist\n",
    "from matplotlib import pyplot\n",
    "# load data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "# create a grid of 3x3 images\n",
    "for i in range(0, 9):\n",
    "\tpyplot.subplot(330 + 1 + i)\n",
    "\tpyplot.imshow(X_train[i], cmap=pyplot.get_cmap('gray'))\n",
    "# show the plot\n",
    "pyplot.show()\n",
    "\n",
    "# Plot images\n",
    "from keras.datasets import mnist\n",
    "from matplotlib import pyplot\n",
    "# load data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "# create a grid of 3x3 images\n",
    "for i in range(0, 9):\n",
    "\tpyplot.subplot(330 + 1 + i)\n",
    "\tpyplot.imshow(X_train[i], cmap=pyplot.get_cmap('gray'))\n",
    "# show the plot\n",
    "pyplot.show()\n",
    "Running this example provides the following image that we can use as a point of comparison with the image preparation and augmentation in the examples below.\n",
    "\n",
    "Example MNIST images\n",
    "Example MNIST images\n",
    "Feature Standardization\n",
    "\n",
    "It is also possible to standardize pixel values across the entire dataset. This is called feature standardization and mirrors the type of standardization often performed for each column in a tabular dataset.\n",
    "\n",
    "You can perform feature standardization by setting the featurewise_center and featurewise_std_normalization arguments on the ImageDataGenerator class. These are in fact set to True by default and creating an instance of ImageDataGenerator with no arguments will have the same effect.\n",
    "\n",
    "\n",
    "# Standardize images across the dataset, mean=0, stdev=1\n",
    "from keras.datasets import mnist\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from matplotlib import pyplot\n",
    "# load data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "# reshape to be [samples][pixels][width][height]\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, 28, 28)\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, 28, 28)\n",
    "# convert from int to float\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "# define data preparation\n",
    "datagen = ImageDataGenerator(featurewise_center=True, featurewise_std_normalization=True)\n",
    "# fit parameters from data\n",
    "datagen.fit(X_train)\n",
    "# configure batch size and retrieve one batch of images\n",
    "for X_batch, y_batch in datagen.flow(X_train, y_train, batch_size=9):\n",
    "\t# create a grid of 3x3 images\n",
    "\tfor i in range(0, 9):\n",
    "\t\tpyplot.subplot(330 + 1 + i)\n",
    "\t\tpyplot.imshow(X_batch[i].reshape(28, 28), cmap=pyplot.get_cmap('gray'))\n",
    "\t# show the plot\n",
    "\tpyplot.show()\n",
    "\tbreak\n",
    "1\n",
    "2\n",
    "\n",
    "# Standardize images across the dataset, mean=0, stdev=1\n",
    "from keras.datasets import mnist\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from matplotlib import pyplot\n",
    "# load data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "# reshape to be [samples][pixels][width][height]\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, 28, 28)\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, 28, 28)\n",
    "# convert from int to float\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "# define data preparation\n",
    "datagen = ImageDataGenerator(featurewise_center=True, featurewise_std_normalization=True)\n",
    "# fit parameters from data\n",
    "datagen.fit(X_train)\n",
    "# configure batch size and retrieve one batch of images\n",
    "for X_batch, y_batch in datagen.flow(X_train, y_train, batch_size=9):\n",
    "\t# create a grid of 3x3 images\n",
    "\tfor i in range(0, 9):\n",
    "\t\tpyplot.subplot(330 + 1 + i)\n",
    "\t\tpyplot.imshow(X_batch[i].reshape(28, 28), cmap=pyplot.get_cmap('gray'))\n",
    "\t# show the plot\n",
    "\tpyplot.show()\n",
    "\tbreak\n",
    "Running this example you can see that the effect is different, seemingly darkening and lightening different digits.\n",
    "\n",
    "Standardized Feature MNIST Images\n",
    "Standardized Feature MNIST Images\n",
    "ZCA Whitening\n",
    "\n",
    "A whitening transform of an image is a linear algebra operation that reduces the redundancy in the matrix of pixel images.\n",
    "\n",
    "Less redundancy in the image is intended to better highlight the structures and features in the image to the learning algorithm.\n",
    "\n",
    "Typically, image whitening is performed using the Principal Component Analysis (PCA) technique. More recently, an alternative called ZCA (learn more in Appendix A of this tech report) shows better results and results in transformed images that keeps all of the original dimensions and unlike PCA, resulting transformed images still look like their originals.\n",
    "\n",
    "You can perform a ZCA whitening transform by setting the zca_whitening argument to True.\n",
    "\n",
    "\n",
    "# ZCA whitening\n",
    "from keras.datasets import mnist\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from matplotlib import pyplot\n",
    "# load data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "# reshape to be [samples][pixels][width][height]\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, 28, 28)\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, 28, 28)\n",
    "# convert from int to float\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "# define data preparation\n",
    "datagen = ImageDataGenerator(zca_whitening=True)\n",
    "# fit parameters from data\n",
    "datagen.fit(X_train)\n",
    "# configure batch size and retrieve one batch of images\n",
    "for X_batch, y_batch in datagen.flow(X_train, y_train, batch_size=9):\n",
    "\t# create a grid of 3x3 images\n",
    "\tfor i in range(0, 9):\n",
    "\t\tpyplot.subplot(330 + 1 + i)\n",
    "\t\tpyplot.imshow(X_batch[i].reshape(28, 28), cmap=pyplot.get_cmap('gray'))\n",
    "\t# show the plot\n",
    "\tpyplot.show()\n",
    "\tbreak\n",
    "1\n",
    "2\n",
    "3\n",
    "4\n",
    "5\n",
    "6\n",
    "7\n",
    "8\n",
    "9\n",
    "10\n",
    "11\n",
    "12\n",
    "13\n",
    "14\n",
    "15\n",
    "16\n",
    "17\n",
    "18\n",
    "19\n",
    "20\n",
    "21\n",
    "22\n",
    "23\n",
    "24\n",
    "25\n",
    "# ZCA whitening\n",
    "from keras.datasets import mnist\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from matplotlib import pyplot\n",
    "# load data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "# reshape to be [samples][pixels][width][height]\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, 28, 28)\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, 28, 28)\n",
    "# convert from int to float\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "# define data preparation\n",
    "datagen = ImageDataGenerator(zca_whitening=True)\n",
    "# fit parameters from data\n",
    "datagen.fit(X_train)\n",
    "# configure batch size and retrieve one batch of images\n",
    "for X_batch, y_batch in datagen.flow(X_train, y_train, batch_size=9):\n",
    "\t# create a grid of 3x3 images\n",
    "\tfor i in range(0, 9):\n",
    "\t\tpyplot.subplot(330 + 1 + i)\n",
    "\t\tpyplot.imshow(X_batch[i].reshape(28, 28), cmap=pyplot.get_cmap('gray'))\n",
    "\t# show the plot\n",
    "\tpyplot.show()\n",
    "\tbreak\n",
    "Running the example, you can see the same general structure in the images and how the outline of each digit has been highlighted.\n",
    "\n",
    "ZCA Whitening MNIST Images\n",
    "ZCA Whitening MNIST Images\n",
    "Random Rotations\n",
    "\n",
    "Sometimes images in your sample data may have varying and different rotations in the scene.\n",
    "\n",
    "You can train your model to better handle rotations of images by artificially and randomly rotating images from your dataset during training.\n",
    "\n",
    "The example below creates random rotations of the MNIST digits up to 90 degrees by setting the rotation_range argument.\n",
    "\n",
    "\n",
    "# Random Rotations\n",
    "from keras.datasets import mnist\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from matplotlib import pyplot\n",
    "# load data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "# reshape to be [samples][pixels][width][height]\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, 28, 28)\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, 28, 28)\n",
    "# convert from int to float\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "# define data preparation\n",
    "datagen = ImageDataGenerator(rotation_range=90)\n",
    "# fit parameters from data\n",
    "datagen.fit(X_train)\n",
    "# configure batch size and retrieve one batch of images\n",
    "for X_batch, y_batch in datagen.flow(X_train, y_train, batch_size=9):\n",
    "\t# create a grid of 3x3 images\n",
    "\tfor i in range(0, 9):\n",
    "\t\tpyplot.subplot(330 + 1 + i)\n",
    "\t\tpyplot.imshow(X_batch[i].reshape(28, 28), cmap=pyplot.get_cmap('gray'))\n",
    "\t# show the plot\n",
    "\tpyplot.show()\n",
    "\tbreak\n",
    "\n",
    "\n",
    "# Random Rotations\n",
    "from keras.datasets import mnist\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from matplotlib import pyplot\n",
    "# load data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "# reshape to be [samples][pixels][width][height]\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, 28, 28)\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, 28, 28)\n",
    "# convert from int to float\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "# define data preparation\n",
    "datagen = ImageDataGenerator(rotation_range=90)\n",
    "# fit parameters from data\n",
    "datagen.fit(X_train)\n",
    "# configure batch size and retrieve one batch of images\n",
    "for X_batch, y_batch in datagen.flow(X_train, y_train, batch_size=9):\n",
    "\t# create a grid of 3x3 images\n",
    "\tfor i in range(0, 9):\n",
    "\t\tpyplot.subplot(330 + 1 + i)\n",
    "\t\tpyplot.imshow(X_batch[i].reshape(28, 28), cmap=pyplot.get_cmap('gray'))\n",
    "\t# show the plot\n",
    "\tpyplot.show()\n",
    "\tbreak\n",
    "Running the example, you can see that images have been rotated left and right up to a limit of 90 degrees. This is not helpful on this problem because the MNIST digits have a normalized orientation, but this transform might be of help when learning from photographs where the objects may have different orientations.\n",
    "\n",
    "Random Rotations of MNIST Images\n",
    "Random Rotations of MNIST Images\n",
    "Random Shifts\n",
    "\n",
    "Objects in your images may not be centered in the frame. They may be off-center in a variety of different ways.\n",
    "\n",
    "You can train your deep learning network to expect and currently handle off-center objects by artificially creating shifted versions of your training data. Keras supports separate horizontal and vertical random shifting of training data by the width_shift_range and height_shift_range arguments.\n",
    "\n",
    "\n",
    "# Random Shifts\n",
    "from keras.datasets import mnist\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from matplotlib import pyplot\n",
    "# load data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "# reshape to be [samples][pixels][width][height]\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, 28, 28)\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, 28, 28)\n",
    "# convert from int to float\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "# define data preparation\n",
    "shift = 0.2\n",
    "datagen = ImageDataGenerator(width_shift_range=shift, height_shift_range=shift)\n",
    "# fit parameters from data\n",
    "datagen.fit(X_train)\n",
    "# configure batch size and retrieve one batch of images\n",
    "for X_batch, y_batch in datagen.flow(X_train, y_train, batch_size=9):\n",
    "\t# create a grid of 3x3 images\n",
    "\tfor i in range(0, 9):\n",
    "\t\tpyplot.subplot(330 + 1 + i)\n",
    "\t\tpyplot.imshow(X_batch[i].reshape(28, 28), cmap=pyplot.get_cmap('gray'))\n",
    "\t# show the plot\n",
    "\tpyplot.show()\n",
    "\tbreak\n",
    "1\n",
    "\n",
    "\n",
    "# Random Shifts\n",
    "from keras.datasets import mnist\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from matplotlib import pyplot\n",
    "# load data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "# reshape to be [samples][pixels][width][height]\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, 28, 28)\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, 28, 28)\n",
    "# convert from int to float\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "# define data preparation\n",
    "shift = 0.2\n",
    "datagen = ImageDataGenerator(width_shift_range=shift, height_shift_range=shift)\n",
    "# fit parameters from data\n",
    "datagen.fit(X_train)\n",
    "# configure batch size and retrieve one batch of images\n",
    "for X_batch, y_batch in datagen.flow(X_train, y_train, batch_size=9):\n",
    "\t# create a grid of 3x3 images\n",
    "\tfor i in range(0, 9):\n",
    "\t\tpyplot.subplot(330 + 1 + i)\n",
    "\t\tpyplot.imshow(X_batch[i].reshape(28, 28), cmap=pyplot.get_cmap('gray'))\n",
    "\t# show the plot\n",
    "\tpyplot.show()\n",
    "\tbreak\n",
    "Running this example creates shifted versions of the digits. Again, this is not required for MNIST as the handwritten digits are already centered, but you can see how this might be useful on more complex problem domains.\n",
    "\n",
    "Random Shifted MNIST Images\n",
    "Random Shifted MNIST Images\n",
    "Random Flips\n",
    "\n",
    "Another augmentation to your image data that can improve performance on large and complex problems is to create random flips of images in your training data.\n",
    "\n",
    "Keras supports random flipping along both the vertical and horizontal axes using the vertical_flip and horizontal_flip arguments.\n",
    "\n",
    "\n",
    "# Random Flips\n",
    "from keras.datasets import mnist\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from matplotlib import pyplot\n",
    "# load data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "# reshape to be [samples][pixels][width][height]\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, 28, 28)\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, 28, 28)\n",
    "# convert from int to float\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "# define data preparation\n",
    "datagen = ImageDataGenerator(horizontal_flip=True, vertical_flip=True)\n",
    "# fit parameters from data\n",
    "datagen.fit(X_train)\n",
    "# configure batch size and retrieve one batch of images\n",
    "for X_batch, y_batch in datagen.flow(X_train, y_train, batch_size=9):\n",
    "\t# create a grid of 3x3 images\n",
    "\tfor i in range(0, 9):\n",
    "\t\tpyplot.subplot(330 + 1 + i)\n",
    "\t\tpyplot.imshow(X_batch[i].reshape(28, 28), cmap=pyplot.get_cmap('gray'))\n",
    "\t# show the plot\n",
    "\tpyplot.show()\n",
    "\tbreak\n",
    "1\n",
    "2\n",
    "3\n",
    "4\n",
    "5\n",
    "6\n",
    "7\n",
    "8\n",
    "9\n",
    "10\n",
    "11\n",
    "12\n",
    "13\n",
    "14\n",
    "15\n",
    "16\n",
    "17\n",
    "18\n",
    "19\n",
    "20\n",
    "21\n",
    "22\n",
    "23\n",
    "24\n",
    "25\n",
    "# Random Flips\n",
    "from keras.datasets import mnist\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from matplotlib import pyplot\n",
    "# load data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "# reshape to be [samples][pixels][width][height]\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, 28, 28)\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, 28, 28)\n",
    "# convert from int to float\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "# define data preparation\n",
    "datagen = ImageDataGenerator(horizontal_flip=True, vertical_flip=True)\n",
    "# fit parameters from data\n",
    "datagen.fit(X_train)\n",
    "# configure batch size and retrieve one batch of images\n",
    "for X_batch, y_batch in datagen.flow(X_train, y_train, batch_size=9):\n",
    "\t# create a grid of 3x3 images\n",
    "\tfor i in range(0, 9):\n",
    "\t\tpyplot.subplot(330 + 1 + i)\n",
    "\t\tpyplot.imshow(X_batch[i].reshape(28, 28), cmap=pyplot.get_cmap('gray'))\n",
    "\t# show the plot\n",
    "\tpyplot.show()\n",
    "\tbreak\n",
    "Running this example you can see flipped digits. Flipping digits is not useful as they will always have the correct left and right orientation, but this may be useful for problems with photographs of objects in a scene that can have a varied orientation.\n",
    "\n",
    "Randomly Flipped MNIST Images\n",
    "Randomly Flipped MNIST Images\n",
    "Saving Augmented Images to File\n",
    "\n",
    "The data preparation and augmentation is performed just in time by Keras.\n",
    "\n",
    "This is efficient in terms of memory, but you may require the exact images used during training. For example, perhaps you would like to use them with a different software package later or only generate them once and use them on multiple different deep learning models or configurations.\n",
    "\n",
    "Keras allows you to save the images generated during training. The directory, filename prefix and image file type can be specified to the flow() function before training. Then, during training, the generated images will be written to file.\n",
    "\n",
    "The example below demonstrates this and writes 9 images to a “images” subdirectory with the prefix “aug” and the file type of PNG.\n",
    "\n",
    "\n",
    "# Save augmented images to file\n",
    "from keras.datasets import mnist\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from matplotlib import pyplot\n",
    "import os\n",
    "# load data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "# reshape to be [samples][pixels][width][height]\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, 28, 28)\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, 28, 28)\n",
    "# convert from int to float\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "# define data preparation\n",
    "datagen = ImageDataGenerator()\n",
    "# fit parameters from data\n",
    "datagen.fit(X_train)\n",
    "# configure batch size and retrieve one batch of images\n",
    "os.makedirs('images')\n",
    "for X_batch, y_batch in datagen.flow(X_train, y_train, batch_size=9, save_to_dir='images', save_prefix='aug', save_format='png'):\n",
    "\t# create a grid of 3x3 images\n",
    "\tfor i in range(0, 9):\n",
    "\t\tpyplot.subplot(330 + 1 + i)\n",
    "\t\tpyplot.imshow(X_batch[i].reshape(28, 28), cmap=pyplot.get_cmap('gray'))\n",
    "\t# show the plot\n",
    "\tpyplot.show()\n",
    "\tbreak\n",
    "\n",
    "\n",
    "\n",
    "# Save augmented images to file\n",
    "from keras.datasets import mnist\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from matplotlib import pyplot\n",
    "import os\n",
    "# load data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "# reshape to be [samples][pixels][width][height]\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, 28, 28)\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, 28, 28)\n",
    "# convert from int to float\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "# define data preparation\n",
    "datagen = ImageDataGenerator()\n",
    "# fit parameters from data\n",
    "datagen.fit(X_train)\n",
    "# configure batch size and retrieve one batch of images\n",
    "os.makedirs('images')\n",
    "for X_batch, y_batch in datagen.flow(X_train, y_train, batch_size=9, save_to_dir='images', save_prefix='aug', save_format='png')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
