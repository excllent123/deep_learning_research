{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2016 Bot \n",
    "\n",
    "### Overview\n",
    "- Introduction \n",
    "- Data ETL\n",
    "- Data Augmentation \n",
    "- Networks Architecture \n",
    "- Training \n",
    "- Model Averaging \n",
    "- Conclusion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os, sys, glob\n",
    "import numpy as np\n",
    "import cv2\n",
    "from skimage.io import imread\n",
    "\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "DEBUG: nvcc STDOUT mod.cu\n",
      "   Creating library C:/Users/kentc/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-Intel64_Family_6_Model_94_Stepping_3_GenuineIntel-2.7.12-64/tmpr43owg/265abc51f7c376c224983485238ff1a5.lib and object C:/Users/kentc/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-Intel64_Family_6_Model_94_Stepping_3_GenuineIntel-2.7.12-64/tmpr43owg/265abc51f7c376c224983485238ff1a5.exp\n",
      "\n",
      "Using gpu device 0: GeForce GTX 970M (CNMeM is disabled, cuDNN 5103)\n",
      "C:\\Users\\kentc\\Anaconda2\\lib\\site-packages\\theano\\sandbox\\cuda\\__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n"
     ]
    }
   ],
   "source": [
    "# Data Augmentation \n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# model build \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import SGD\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from keras.models import model_from_json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Conf:\n",
    "    def __init__(self, confPath):\n",
    "        # load and store the configuration and update the object's dictionary\n",
    "        conf = json.loads(open(confPath).read())\n",
    "        self.__dict__.update(conf)\n",
    "\n",
    "    def __getitem__(self, k):\n",
    "        # return the value associated with the supplied key\n",
    "        return self.__dict__.get(k, None)\n",
    "    \n",
    "    \n",
    "def auto_resized(img,size):\n",
    "    '''size = (width,height)'''\n",
    "    size = tuple(size)\n",
    "    resize_img = cv2.resize(img, size, interpolation=cv2.INTER_LINEAR)\n",
    "    return resize_img\n",
    "\n",
    "def TrainFilePath(folderPath, constrain=None, **kargs):\n",
    "    '''\n",
    "    (1) Output filepath and calssName\n",
    "    (2) folderPath \n",
    "          --label_1\n",
    "           -- xxx.jpg\n",
    "    '''\n",
    "    assert folderPath[-1]!='/'\n",
    "    if constrain is None:\n",
    "        constrain = ('avi', 'mp4','png','jpg') \n",
    "    for (rootDir, dirNames, fileNames) in os.walk(folderPath):\n",
    "        for fileName in fileNames:\n",
    "            if fileName.split('.')[-1] in constrain:\n",
    "                yield (os.path.join(rootDir, fileName)) \n",
    "                \n",
    "#img_channels = 3\n",
    "def genTrX(filePath, resolution, img_channels=3):\n",
    "    assert type(resolution) == tuple\n",
    "    img = auto_resized(imread(filePath),resolution)  #conf['sliding_size']\n",
    "    if img_channels==1:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    elif img_channels==3:\n",
    "        img = img[:,:,:3]\n",
    "    return img\n",
    "                \n",
    "def load_training(folderList, img_rows, img_cols, img_channels):\n",
    "    TrY = []\n",
    "    TrX = []\n",
    "    TrY_template = np.eye(len(folderList))\n",
    "    for eyeId, folderPath in enumerate(folderList):\n",
    "        for imgPath in TrainFilePath(folderPath) :\n",
    "            TrY.append(TrY_template[eyeId])\n",
    "            TrX.append(genTrX(imgPath, (img_rows,img_cols), img_channels))\n",
    "    print (len(TrX))\n",
    "    return TrX, TrY\n",
    "\n",
    "def create_folderList(rootDir):\n",
    "    result=[]\n",
    "    for a in os.listdir(rootDir):\n",
    "        a = os.path.join(rootDir, a)\n",
    "        if os.path.isdir(a):\n",
    "            result.append(a) \n",
    "    return result\n",
    "\n",
    "\n",
    "def reshapeShuffle(TrX, TrY, img_rows, img_cols, img_channels):\n",
    "    trainX = np.asarray(TrX, dtype = np.uint8)\n",
    "    trainX = trainX.reshape(trainX.shape[0], img_channels, img_rows, img_cols)\n",
    "    trainX = trainX.astype('float32')\n",
    "    trainY = np.asarray(TrY, dtype = np.float32)\n",
    "    # shuffle\n",
    "    trainX , trainY = shuffle(trainX,trainY)\n",
    "    print ('Train_X : ',trainX.shape,'Train_Y' ,trainY.shape)\n",
    "    return trainX , trainY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116481\n"
     ]
    }
   ],
   "source": [
    "ROOT_Dir = 'D:\\\\2016bot_cv'\n",
    "\n",
    "img_rows= 64\n",
    "\n",
    "img_cols= 64\n",
    "\n",
    "img_channels=3\n",
    "\n",
    "folderList = create_folderList(ROOT_Dir)\n",
    "\n",
    "Train_X, Train_Y = load_training(folderList, img_rows, img_cols, img_channels)\n",
    "\n",
    "\n",
    "\n",
    "#TrainFilePath('D:\\2015')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Train_X : ', (116481L, 3L, 64L, 64L), 'Train_Y', (116481L, 12L))\n"
     ]
    }
   ],
   "source": [
    "train_X , train_Y = reshapeShuffle(Train_X, Train_Y, img_rows, img_cols, img_channels=img_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gen_Img = ImageDataGenerator(featurewise_center=True,\n",
    "    samplewise_center=False,\n",
    "    featurewise_std_normalization=True,\n",
    "    samplewise_std_normalization=False,\n",
    "    zca_whitening=False,\n",
    "    rotation_range=20.,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.,\n",
    "    channel_shift_range=0.,\n",
    "    fill_mode='nearest',\n",
    "    cval=0.,\n",
    "    horizontal_flip=False,\n",
    "    vertical_flip=False,\n",
    "    rescale=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen_Img.fit(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Flatten, Dense, Dropout\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "def VGG_19(img_rows,img_cols,weights_path=None):\n",
    "    model = Sequential()\n",
    "    model.add(ZeroPadding2D((1,1),input_shape=(3,img_rows,img_cols)))\n",
    "    model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(5600, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(5600, activation='relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(550, activation='softmax'))\n",
    "    model.add(Dense(12, activation='softmax'))   \n",
    "    if weights_path:\n",
    "        model.load_weights(weights_path)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def simpleVGG(img_rows,img_cols,weights_path=None):\n",
    "    model = Sequential()\n",
    "    model.add(ZeroPadding2D((1,1),input_shape=(3,img_rows,img_cols)))\n",
    "    model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(800, activation='relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(800, activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(250, activation='softmax'))\n",
    "    model.add(Dense(12, activation='softmax'))   \n",
    "    if weights_path:\n",
    "        model.load_weights(weights_path)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def easyVGG(img_rows,img_cols,weights_path=None):\n",
    "    model = Sequential()\n",
    "    model.add(ZeroPadding2D((1,1),input_shape=(3,img_rows,img_cols)))\n",
    "    model.add(Convolution2D(32, 3, 3))\n",
    "    model.add(MaxPooling2D((3,3), strides=(2,2)))\n",
    "\n",
    "    model.add(Convolution2D(64, 3, 3))\n",
    "    model.add(MaxPooling2D((3,3), strides=(2,2)))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1500, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(1000, activation='tanh'))\n",
    "    model.add(Dense(200, activation='softmax'))\n",
    "    model.add(Dense(12, activation='softmax'))   \n",
    "    if weights_path:\n",
    "        model.load_weights(weights_path)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "zeropadding2d_39 (ZeroPadding2D) (None, 3, 66, 66)     0           zeropadding2d_input_10[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_42 (Convolution2D) (None, 32, 64, 64)    896         zeropadding2d_39[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_19 (MaxPooling2D)   (None, 32, 31, 31)    0           convolution2d_42[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_43 (Convolution2D) (None, 64, 29, 29)    18496       maxpooling2d_19[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_20 (MaxPooling2D)   (None, 64, 14, 14)    0           convolution2d_43[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "flatten_11 (Flatten)             (None, 12544)         0           maxpooling2d_20[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dense_32 (Dense)                 (None, 1500)          18817500    flatten_11[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)             (None, 1500)          0           dense_32[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_33 (Dense)                 (None, 1000)          1501000     dropout_14[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dense_34 (Dense)                 (None, 200)           200200      dense_33[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_35 (Dense)                 (None, 12)            2412        dense_34[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 20540504\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#model = VGG_19(img_rows,img_cols)\n",
    "model = easyVGG(img_rows,img_cols)\n",
    "#https://gist.github.com/baraldilorenzo/8d096f48a1be4a2d660d\n",
    "sgd = SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(optimizer=sgd, loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "93184/93184 [==============================] - 283s - loss: 2.4717 - acc: 0.1193 - val_loss: 2.4753 - val_acc: 0.1023\n",
      "Epoch 2/50\n",
      "93184/93184 [==============================] - 261s - loss: 2.4555 - acc: 0.1371 - val_loss: 2.4804 - val_acc: 0.1026\n",
      "Epoch 3/50\n",
      "93184/93184 [==============================] - 263s - loss: 2.4393 - acc: 0.1432 - val_loss: 2.4940 - val_acc: 0.1027\n",
      "Epoch 4/50\n",
      "93184/93184 [==============================] - 263s - loss: 2.4109 - acc: 0.1468 - val_loss: 2.5168 - val_acc: 0.1036\n",
      "Epoch 5/50\n",
      "93184/93184 [==============================] - 261s - loss: 2.3892 - acc: 0.1486 - val_loss: 2.5512 - val_acc: 0.1024\n",
      "Epoch 6/50\n",
      "93184/93184 [==============================] - 262s - loss: 2.3725 - acc: 0.1503 - val_loss: 2.4599 - val_acc: 0.1256\n",
      "Epoch 7/50\n",
      "93184/93184 [==============================] - 260s - loss: 2.3600 - acc: 0.1503 - val_loss: 2.5715 - val_acc: 0.1084\n",
      "Epoch 8/50\n",
      "93184/93184 [==============================] - 258s - loss: 2.3468 - acc: 0.1506 - val_loss: 2.4585 - val_acc: 0.1251\n",
      "Epoch 9/50\n",
      "93184/93184 [==============================] - 258s - loss: 2.3345 - acc: 0.1518 - val_loss: 2.3460 - val_acc: 0.1461\n",
      "Epoch 10/50\n",
      "93184/93184 [==============================] - 258s - loss: 2.3237 - acc: 0.1647 - val_loss: 2.5267 - val_acc: 0.1237\n",
      "Epoch 11/50\n",
      "93184/93184 [==============================] - 258s - loss: 2.3126 - acc: 0.1781 - val_loss: 2.4173 - val_acc: 0.1464\n",
      "Epoch 12/50\n",
      "93184/93184 [==============================] - 261s - loss: 2.3021 - acc: 0.1825 - val_loss: 2.4123 - val_acc: 0.1498\n",
      "Epoch 13/50\n",
      "93184/93184 [==============================] - 261s - loss: 2.2919 - acc: 0.1867 - val_loss: 2.6112 - val_acc: 0.1275\n",
      "Epoch 14/50\n",
      "93184/93184 [==============================] - 261s - loss: 2.2832 - acc: 0.1903 - val_loss: 2.5490 - val_acc: 0.1431\n",
      "Epoch 15/50\n",
      "93184/93184 [==============================] - 261s - loss: 2.2743 - acc: 0.1933 - val_loss: 2.5339 - val_acc: 0.1528\n",
      "Epoch 16/50\n",
      "93184/93184 [==============================] - 260s - loss: 2.2656 - acc: 0.1972 - val_loss: 2.5556 - val_acc: 0.1488\n",
      "Epoch 17/50\n",
      "93184/93184 [==============================] - 261s - loss: 2.2575 - acc: 0.1992 - val_loss: 2.4008 - val_acc: 0.1710\n",
      "Epoch 18/50\n",
      "93184/93184 [==============================] - 259s - loss: 2.2491 - acc: 0.2034 - val_loss: 2.3501 - val_acc: 0.1803\n",
      "Epoch 19/50\n",
      "93184/93184 [==============================] - 258s - loss: 2.2401 - acc: 0.2057 - val_loss: 2.4658 - val_acc: 0.1583\n",
      "Epoch 20/50\n",
      "93184/93184 [==============================] - 258s - loss: 2.2325 - acc: 0.2075 - val_loss: 2.4661 - val_acc: 0.1566\n",
      "Epoch 21/50\n",
      "93184/93184 [==============================] - 258s - loss: 2.2233 - acc: 0.2102 - val_loss: 2.4496 - val_acc: 0.1562\n",
      "Epoch 22/50\n",
      "93184/93184 [==============================] - 258s - loss: 2.2172 - acc: 0.2128 - val_loss: 2.4660 - val_acc: 0.1674\n",
      "Epoch 23/50\n",
      "93184/93184 [==============================] - 258s - loss: 2.2091 - acc: 0.2145 - val_loss: 2.5193 - val_acc: 0.1577\n",
      "Epoch 24/50\n",
      "93184/93184 [==============================] - 258s - loss: 2.2045 - acc: 0.2183 - val_loss: 2.5293 - val_acc: 0.1516\n",
      "Epoch 25/50\n",
      "93184/93184 [==============================] - 258s - loss: 2.1976 - acc: 0.2220 - val_loss: 2.5076 - val_acc: 0.1578\n",
      "Epoch 26/50\n",
      "93184/93184 [==============================] - 258s - loss: 2.1918 - acc: 0.2267 - val_loss: 2.5900 - val_acc: 0.1498\n",
      "Epoch 27/50\n",
      "93184/93184 [==============================] - 258s - loss: 2.1839 - acc: 0.2290 - val_loss: 2.4643 - val_acc: 0.1589\n",
      "Epoch 28/50\n",
      "93184/93184 [==============================] - 258s - loss: 2.1798 - acc: 0.2322 - val_loss: 2.6198 - val_acc: 0.1512\n",
      "Epoch 29/50\n",
      "93184/93184 [==============================] - 258s - loss: 2.1742 - acc: 0.2348 - val_loss: 2.8198 - val_acc: 0.1347\n",
      "Epoch 30/50\n",
      "93184/93184 [==============================] - 258s - loss: 2.1667 - acc: 0.2388 - val_loss: 2.7097 - val_acc: 0.1407\n",
      "Epoch 31/50\n",
      "93184/93184 [==============================] - 258s - loss: 2.1587 - acc: 0.2424 - val_loss: 2.8251 - val_acc: 0.1341\n",
      "Epoch 32/50\n",
      "93184/93184 [==============================] - 258s - loss: 2.1540 - acc: 0.2444 - val_loss: 2.7492 - val_acc: 0.1410\n",
      "Epoch 33/50\n",
      "93184/93184 [==============================] - 259s - loss: 2.1483 - acc: 0.2476 - val_loss: 2.8054 - val_acc: 0.1289\n",
      "Epoch 34/50\n",
      "93184/93184 [==============================] - 258s - loss: 2.1419 - acc: 0.2487 - val_loss: 2.7061 - val_acc: 0.1445\n",
      "Epoch 35/50\n",
      "93184/93184 [==============================] - 258s - loss: 2.1368 - acc: 0.2498 - val_loss: 2.6375 - val_acc: 0.1483\n",
      "Epoch 36/50\n",
      "93184/93184 [==============================] - 260s - loss: 2.1318 - acc: 0.2534 - val_loss: 2.5450 - val_acc: 0.1601\n",
      "Epoch 37/50\n",
      "93184/93184 [==============================] - 259s - loss: 2.1280 - acc: 0.2526 - val_loss: 2.5966 - val_acc: 0.1531\n",
      "Epoch 38/50\n",
      "93184/93184 [==============================] - 258s - loss: 2.1231 - acc: 0.2545 - val_loss: 2.9582 - val_acc: 0.1247\n",
      "Epoch 39/50\n",
      "93184/93184 [==============================] - 260s - loss: 2.1177 - acc: 0.2562 - val_loss: 2.6980 - val_acc: 0.1502\n",
      "Epoch 40/50\n",
      "93184/93184 [==============================] - 258s - loss: 2.1139 - acc: 0.2582 - val_loss: 2.6451 - val_acc: 0.1474\n",
      "Epoch 41/50\n",
      "93184/93184 [==============================] - 259s - loss: 2.1088 - acc: 0.2577 - val_loss: 2.6557 - val_acc: 0.1481\n",
      "Epoch 42/50\n",
      "93184/93184 [==============================] - 258s - loss: 2.1045 - acc: 0.2589 - val_loss: 3.0001 - val_acc: 0.1229\n",
      "Epoch 43/50\n",
      "93184/93184 [==============================] - 258s - loss: 2.0985 - acc: 0.2621 - val_loss: 2.5833 - val_acc: 0.1566\n",
      "Epoch 44/50\n",
      "93184/93184 [==============================] - 259s - loss: 2.0959 - acc: 0.2640 - val_loss: 2.6530 - val_acc: 0.1492\n",
      "Epoch 45/50\n",
      "93184/93184 [==============================] - 258s - loss: 2.0900 - acc: 0.2639 - val_loss: 2.6453 - val_acc: 0.1566\n",
      "Epoch 46/50\n",
      "93184/93184 [==============================] - 259s - loss: 2.0879 - acc: 0.2650 - val_loss: 2.7789 - val_acc: 0.1422\n",
      "Epoch 47/50\n",
      "93184/93184 [==============================] - 258s - loss: 2.0853 - acc: 0.2642 - val_loss: 2.7218 - val_acc: 0.1523\n",
      "Epoch 48/50\n",
      "93184/93184 [==============================] - 259s - loss: 2.0796 - acc: 0.2670 - val_loss: 2.8816 - val_acc: 0.1424\n",
      "Epoch 49/50\n",
      "93184/93184 [==============================] - 258s - loss: 2.0754 - acc: 0.2675 - val_loss: 2.7139 - val_acc: 0.1571\n",
      "Epoch 50/50\n",
      "93184/93184 [==============================] - 258s - loss: 2.0738 - acc: 0.2704 - val_loss: 2.6400 - val_acc: 0.1608\n",
      "Epoch 1/50\n",
      "93185/93185 [==============================] - 261s - loss: 2.0816 - acc: 0.2682 - val_loss: 3.0886 - val_acc: 0.1277\n",
      "Epoch 2/50\n",
      "93185/93185 [==============================] - 260s - loss: 2.0761 - acc: 0.2702 - val_loss: 2.7237 - val_acc: 0.1496\n",
      "Epoch 3/50\n",
      "93185/93185 [==============================] - 260s - loss: 2.0715 - acc: 0.2716 - val_loss: 2.9810 - val_acc: 0.1324\n",
      "Epoch 4/50\n",
      "93185/93185 [==============================] - 259s - loss: 2.0646 - acc: 0.2719 - val_loss: 2.7088 - val_acc: 0.1589\n",
      "Epoch 5/50\n",
      "93185/93185 [==============================] - 260s - loss: 2.0616 - acc: 0.2735 - val_loss: 2.8943 - val_acc: 0.1380\n",
      "Epoch 6/50\n",
      "93185/93185 [==============================] - 259s - loss: 2.0580 - acc: 0.2741 - val_loss: 2.9532 - val_acc: 0.1361\n",
      "Epoch 7/50\n",
      "93185/93185 [==============================] - 266s - loss: 2.0521 - acc: 0.2769 - val_loss: 2.7554 - val_acc: 0.1556\n",
      "Epoch 8/50\n",
      "93185/93185 [==============================] - 261s - loss: 2.0474 - acc: 0.2784 - val_loss: 2.8372 - val_acc: 0.1411\n",
      "Epoch 9/50\n",
      "93185/93185 [==============================] - 259s - loss: 2.0461 - acc: 0.2790 - val_loss: 2.9356 - val_acc: 0.1382\n",
      "Epoch 10/50\n",
      "93185/93185 [==============================] - 261s - loss: 2.0403 - acc: 0.2808 - val_loss: 2.7743 - val_acc: 0.1517\n",
      "Epoch 11/50\n",
      "93185/93185 [==============================] - 259s - loss: 2.0363 - acc: 0.2827 - val_loss: 3.1284 - val_acc: 0.1287\n",
      "Epoch 12/50\n",
      "93185/93185 [==============================] - 260s - loss: 2.0327 - acc: 0.2823 - val_loss: 3.0078 - val_acc: 0.1332\n",
      "Epoch 13/50\n",
      "93185/93185 [==============================] - 259s - loss: 2.0298 - acc: 0.2841 - val_loss: 2.7732 - val_acc: 0.1511\n",
      "Epoch 14/50\n",
      "93185/93185 [==============================] - 260s - loss: 2.0259 - acc: 0.2844 - val_loss: 3.2048 - val_acc: 0.1262\n",
      "Epoch 15/50\n",
      "93185/93185 [==============================] - 260s - loss: 2.0212 - acc: 0.2853 - val_loss: 2.9919 - val_acc: 0.1378\n",
      "Epoch 16/50\n",
      "93185/93185 [==============================] - 259s - loss: 2.0165 - acc: 0.2886 - val_loss: 2.8133 - val_acc: 0.1488\n",
      "Epoch 17/50\n",
      "93185/93185 [==============================] - 259s - loss: 2.0133 - acc: 0.2892 - val_loss: 3.0771 - val_acc: 0.1335\n",
      "Epoch 18/50\n",
      "93185/93185 [==============================] - 260s - loss: 2.0107 - acc: 0.2893 - val_loss: 3.0897 - val_acc: 0.1315\n",
      "Epoch 19/50\n",
      "93185/93185 [==============================] - 260s - loss: 2.0060 - acc: 0.2910 - val_loss: 3.1630 - val_acc: 0.1280\n",
      "Epoch 20/50\n",
      "93185/93185 [==============================] - 259s - loss: 2.0012 - acc: 0.2939 - val_loss: 2.9740 - val_acc: 0.1399\n",
      "Epoch 21/50\n",
      "93185/93185 [==============================] - 259s - loss: 1.9970 - acc: 0.2946 - val_loss: 2.9883 - val_acc: 0.1404\n",
      "Epoch 22/50\n",
      "93185/93185 [==============================] - 259s - loss: 1.9933 - acc: 0.2962 - val_loss: 3.3622 - val_acc: 0.1220\n",
      "Epoch 23/50\n",
      "93185/93185 [==============================] - 259s - loss: 1.9889 - acc: 0.2970 - val_loss: 2.9533 - val_acc: 0.1434\n",
      "Epoch 24/50\n",
      "93185/93185 [==============================] - 260s - loss: 1.9862 - acc: 0.2980 - val_loss: 3.1128 - val_acc: 0.1317\n",
      "Epoch 25/50\n",
      "93185/93185 [==============================] - 259s - loss: 1.9828 - acc: 0.3010 - val_loss: 3.3538 - val_acc: 0.1217\n",
      "Epoch 26/50\n",
      "93185/93185 [==============================] - 259s - loss: 1.9745 - acc: 0.3033 - val_loss: 3.1676 - val_acc: 0.1289\n",
      "Epoch 27/50\n",
      "93185/93185 [==============================] - 260s - loss: 1.9717 - acc: 0.3025 - val_loss: 3.1996 - val_acc: 0.1281\n",
      "Epoch 28/50\n",
      "93185/93185 [==============================] - 260s - loss: 1.9690 - acc: 0.3042 - val_loss: 3.2570 - val_acc: 0.1258\n",
      "Epoch 29/50\n",
      "93185/93185 [==============================] - 259s - loss: 1.9651 - acc: 0.3052 - val_loss: 3.3652 - val_acc: 0.1212\n",
      "Epoch 30/50\n",
      "93185/93185 [==============================] - 260s - loss: 1.9611 - acc: 0.3073 - val_loss: 2.9672 - val_acc: 0.1426\n",
      "Epoch 31/50\n",
      "93185/93185 [==============================] - 260s - loss: 1.9553 - acc: 0.3092 - val_loss: 3.2757 - val_acc: 0.1285\n",
      "Epoch 32/50\n",
      "93185/93185 [==============================] - 260s - loss: 1.9542 - acc: 0.3075 - val_loss: 3.1145 - val_acc: 0.1371\n",
      "Epoch 33/50\n",
      "93185/93185 [==============================] - 259s - loss: 1.9459 - acc: 0.3104 - val_loss: 3.0150 - val_acc: 0.1440\n",
      "Epoch 34/50\n",
      "93185/93185 [==============================] - 259s - loss: 1.9440 - acc: 0.3121 - val_loss: 3.0941 - val_acc: 0.1377\n",
      "Epoch 35/50\n",
      "93185/93185 [==============================] - 260s - loss: 1.9410 - acc: 0.3144 - val_loss: 3.1841 - val_acc: 0.1334\n",
      "Epoch 36/50\n",
      "93185/93185 [==============================] - 260s - loss: 1.9339 - acc: 0.3142 - val_loss: 2.9522 - val_acc: 0.1498\n",
      "Epoch 37/50\n",
      "93185/93185 [==============================] - 260s - loss: 1.9319 - acc: 0.3170 - val_loss: 3.1019 - val_acc: 0.1362\n",
      "Epoch 38/50\n",
      "93185/93185 [==============================] - 260s - loss: 1.9269 - acc: 0.3174 - val_loss: 3.0516 - val_acc: 0.1466\n",
      "Epoch 39/50\n",
      "93185/93185 [==============================] - 260s - loss: 1.9220 - acc: 0.3193 - val_loss: 3.0964 - val_acc: 0.1401\n",
      "Epoch 40/50\n",
      "93185/93185 [==============================] - 260s - loss: 1.9173 - acc: 0.3208 - val_loss: 3.2750 - val_acc: 0.1289\n",
      "Epoch 41/50\n",
      "93185/93185 [==============================] - 260s - loss: 1.9134 - acc: 0.3221 - val_loss: 3.3511 - val_acc: 0.1283\n",
      "Epoch 42/50\n",
      "93185/93185 [==============================] - 260s - loss: 1.9090 - acc: 0.3254 - val_loss: 3.1261 - val_acc: 0.1394\n",
      "Epoch 43/50\n",
      "93185/93185 [==============================] - 260s - loss: 1.9070 - acc: 0.3236 - val_loss: 2.9784 - val_acc: 0.1532\n",
      "Epoch 44/50\n",
      "93185/93185 [==============================] - 262s - loss: 1.9008 - acc: 0.3241 - val_loss: 3.1091 - val_acc: 0.1387\n",
      "Epoch 45/50\n",
      "93185/93185 [==============================] - 262s - loss: 1.8973 - acc: 0.3272 - val_loss: 2.9626 - val_acc: 0.1535\n",
      "Epoch 46/50\n",
      "72354/93185 [======================>.......]"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "I/O operation on closed file",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-a3bab994751b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;31m# fits the model on batches with real-time data augmentation:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     model.fit_generator(gen_Img.flow(Tr_X, Tr_Y, batch_size=62),\n\u001b[1;32m---> 11\u001b[1;33m                     samples_per_epoch=len(Tr_X), nb_epoch=50, validation_data=(Te_X, Te_Y))\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\kentc\\Anaconda2\\lib\\site-packages\\keras\\models.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, **kwargs)\u001b[0m\n\u001b[0;32m    659\u001b[0m                                         \u001b[0mnb_val_samples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnb_val_samples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    660\u001b[0m                                         \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 661\u001b[1;33m                                         max_q_size=max_q_size)\n\u001b[0m\u001b[0;32m    662\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    663\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mevaluate_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_q_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\kentc\\Anaconda2\\lib\\site-packages\\keras\\engine\\training.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size)\u001b[0m\n\u001b[0;32m   1421\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1422\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1423\u001b[1;33m                 \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1424\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1425\u001b[0m                 \u001b[1;31m# construct epoch logs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\kentc\\Anaconda2\\lib\\site-packages\\keras\\callbacks.pyc\u001b[0m in \u001b[0;36mon_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[0mt_before_callbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m             \u001b[0mcallback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delta_ts_batch_end\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mt_before_callbacks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[0mdelta_t_median\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delta_ts_batch_end\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\kentc\\Anaconda2\\lib\\site-packages\\keras\\callbacks.pyc\u001b[0m in \u001b[0;36mon_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    186\u001b[0m         \u001b[1;31m# will be handled by on_epoch_end\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseen\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'nb_sample'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 188\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\kentc\\Anaconda2\\lib\\site-packages\\keras\\utils\\generic_utils.pyc\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, current, values, force)\u001b[0m\n\u001b[0;32m    117\u001b[0m                 \u001b[0minfo\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprev_total_width\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtotal_width\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;34m\" \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m             \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m             \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\kentc\\Anaconda2\\lib\\site-packages\\ipykernel\\iostream.pyc\u001b[0m in \u001b[0;36mwrite\u001b[1;34m(self, string)\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m             \u001b[0mis_child\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_master_process\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 317\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    318\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_child\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    319\u001b[0m                 \u001b[1;31m# newlines imply flush in subprocesses\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: I/O operation on closed file"
     ]
    }
   ],
   "source": [
    "\n",
    "kf = KFold(len(train_Y), n_folds=5)\n",
    "for train, test in kf:\n",
    "    #print (train, test)\n",
    "    Tr_X = train_X[train]\n",
    "    Te_X = train_X[test]\n",
    "    Tr_Y = train_Y[train]\n",
    "    Te_Y = train_Y[test]\n",
    "    # fits the model on batches with real-time data augmentation:\n",
    "    model.fit_generator(gen_Img.flow(Tr_X, Tr_Y, batch_size=62),\n",
    "                    samples_per_epoch=len(Tr_X), nb_epoch=50, validation_data=(Te_X, Te_Y))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[ 0.06765255,  0.05522573,  0.166471  ,  0.0549007 ,  0.23201817,\n",
      "         0.07208199,  0.02534884,  0.0910301 ,  0.09874104,  0.04685798,\n",
      "         0.05006972,  0.03960211]]), '--><--', 6)\n",
      "1/1 [==============================] - 0s\n",
      "(array([4], dtype=int64), '--><--', 6)\n",
      "(array([[ 0.14910103,  0.01401548,  0.18644281,  0.00969182,  0.00395913,\n",
      "         0.57948172,  0.00097937,  0.0009457 ,  0.0021289 ,  0.02555787,\n",
      "         0.0246339 ,  0.00306222]]), '--><--', 5)\n",
      "1/1 [==============================] - 0s\n",
      "(array([5], dtype=int64), '--><--', 5)\n",
      "(array([[ 0.14858544,  0.0128876 ,  0.18008217,  0.00885729,  0.00325871,\n",
      "         0.59287524,  0.00084462,  0.00077624,  0.00179375,  0.02414658,\n",
      "         0.02314821,  0.00274419]]), '--><--', 2)\n",
      "1/1 [==============================] - 0s\n",
      "(array([5], dtype=int64), '--><--', 2)\n",
      "(array([[ 0.07450308,  0.05318019,  0.19474643,  0.04515579,  0.22066508,\n",
      "         0.12756181,  0.01942939,  0.06375183,  0.07406041,  0.04869528,\n",
      "         0.05303335,  0.02521732]]), '--><--', 6)\n",
      "1/1 [==============================] - 0s\n",
      "(array([4], dtype=int64), '--><--', 6)\n",
      "(array([[ 0.14008538,  0.03815255,  0.25580463,  0.02961258,  0.04334131,\n",
      "         0.34555092,  0.00638666,  0.01166245,  0.01855344,  0.04843327,\n",
      "         0.04965533,  0.01276143]]), '--><--', 6)\n",
      "1/1 [==============================] - 0s\n",
      "(array([5], dtype=int64), '--><--', 6)\n",
      "(array([[ 0.05026536,  0.06350743,  0.13050556,  0.0579921 ,  0.24611624,\n",
      "         0.05578086,  0.03516524,  0.10448503,  0.11248294,  0.05174258,\n",
      "         0.05385273,  0.03810395]]), '--><--', 1)\n",
      "1/1 [==============================] - 0s\n",
      "(array([4], dtype=int64), '--><--', 1)\n",
      "(array([[ 0.14271533,  0.0357942 ,  0.2539109 ,  0.02753132,  0.03698098,\n",
      "         0.36570668,  0.00560475,  0.00981036,  0.0160042 ,  0.04667424,\n",
      "         0.04768267,  0.01158424]]), '--><--', 8)\n",
      "1/1 [==============================] - 0s\n",
      "(array([5], dtype=int64), '--><--', 8)\n",
      "(array([[  1.46775663e-01,   1.14550078e-02,   1.71321139e-01,\n",
      "          7.78854638e-03,   2.52580410e-03,   6.11653090e-01,\n",
      "          6.88892440e-04,   5.95009653e-04,   1.42257975e-03,\n",
      "          2.22401731e-02,   2.11915802e-02,   2.34252028e-03]]), '--><--', 11)\n",
      "1/1 [==============================] - 0s\n",
      "(array([5], dtype=int64), '--><--', 11)\n",
      "(array([[ 0.15891938,  0.02103515,  0.21268009,  0.01520948,  0.00760779,\n",
      "         0.5027253 ,  0.00193011,  0.00205929,  0.004253  ,  0.03474316,\n",
      "         0.03349267,  0.00534453]]), '--><--', 8)\n",
      "1/1 [==============================] - 0s\n",
      "(array([5], dtype=int64), '--><--', 8)\n"
     ]
    }
   ],
   "source": [
    "for x in range(100,1000,100):\n",
    "    print (model.predict(Te_X[x].reshape(1,img_channels,img_rows,img_rows)) ,'--><--', np.argmax(Te_Y[x]) )\n",
    "    print (model.predict_classes(Te_X[x].reshape(1,img_channels,img_rows,img_rows)) ,'--><--', np.argmax(Te_Y[x]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model weight as ../hub/model/2016bot_0001.h5\n",
      "saving model struct as ../hub/model/2016bot_0001.json\n"
     ]
    }
   ],
   "source": [
    "model_name='2016bot_0001'\n",
    "model.save_weights('../hub/model/{}.h5'.format(model_name))\n",
    "print ('saving model weight as ' + '../hub/model/{}.h5'.format(model_name))\n",
    "\n",
    "\n",
    "\n",
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"../hub/model/{}.json\".format(model_name), \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "print ('saving model struct as ' + \"../hub/model/{}.json\".format(model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "output = open('X_62.pkl', 'wb')\n",
    "\n",
    "# Pickle dictionary using protocol 0.\n",
    "pickle.dump(train_X, output)\n",
    "output.close()\n",
    "\n",
    "output2 = open('Y_62.pkl', 'wb')\n",
    "pickle.dump(train_X, output2)\n",
    "output2.close()\n",
    "# Pickle the list using the highest protocol available.\n",
    "# pickle.dump(selfref_list, output, -1)\n",
    "\n",
    "# output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "score = model.evaluate(Te_X, Te_Y, verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Clean the GPU memory\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.predict_proba(Te_X[3].reshape(1,img_channels,img_rows,img_rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class ConvNetFactory:\n",
    "\tdef __init__(self):\n",
    "\t\tpass\n",
    "\n",
    "\t@staticmethod\n",
    "\tdef build(name, *args, **kargs):\n",
    "\t\t# define the network (i.e., string => function) mappings\n",
    "\t\tmappings = {\n",
    "\t\t\t\"shallownet\": ConvNetFactory.ShallowNet,\n",
    "\t\t\t\"lenet\": ConvNetFactory.LeNet,\n",
    "\t\t\t\"karpathynet\": ConvNetFactory.KarpathyNet,\n",
    "\t\t\t\"minivggnet\": ConvNetFactory.MiniVGGNet}\n",
    "\n",
    "\t\t# grab the builder function from the mappings dictionary\n",
    "\t\tbuilder = mappings.get(name, None)\n",
    "\n",
    "\t\t# if the builder is None, then there is not a function that can be used\n",
    "\t\t# to build to the network, so return None\n",
    "\t\tif builder is None:\n",
    "\t\t\treturn None\n",
    "\n",
    "\t\t# otherwise, build the network architecture\n",
    "\t\treturn builder(*args, **kargs)\n",
    "\n",
    "\t@staticmethod\n",
    "\tdef ShallowNet(numChannels, imgRows, imgCols, numClasses, **kwargs):\n",
    "\t\t# initialzie the model\n",
    "\t\tmodel = Sequential()\n",
    "\n",
    "\t\t# define the first (and only) CONV => RELU layer\n",
    "\t\tmodel.add(Convolution2D(32, 3, 3, border_mode=\"same\",\n",
    "\t\t\tinput_shape=(numChannels, imgRows, imgCols)))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\n",
    "\t\t# add a FC layer followed by the soft-max classifier\n",
    "\t\tmodel.add(Flatten())\n",
    "\t\tmodel.add(Dense(numClasses))\n",
    "\t\tmodel.add(Activation(\"softmax\"))\n",
    "\n",
    "\t\t# return the network architecture\n",
    "\t\treturn model\n",
    "\n",
    "\t@staticmethod\n",
    "\tdef LeNet(numChannels, imgRows, imgCols, numClasses, activation=\"tanh\", **kwargs):\n",
    "\t\t# initialize the model\n",
    "\t\tmodel = Sequential()\n",
    "\n",
    "\t\t# define the first set of CONV => ACTIVATION => POOL layers\n",
    "\t\tmodel.add(Convolution2D(20, 5, 5, border_mode=\"same\",\n",
    "\t\t\tinput_shape=(numChannels, imgRows, imgCols)))\n",
    "\t\tmodel.add(Activation(activation))\n",
    "\t\tmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "\t\t# define the second set of CONV => ACTIVATION => POOL layers\n",
    "\t\tmodel.add(Convolution2D(50, 5, 5, border_mode=\"same\"))\n",
    "\t\tmodel.add(Activation(activation))\n",
    "\t\tmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "\t\t# define the first FC => ACTIVATION layers\n",
    "\t\tmodel.add(Flatten())\n",
    "\t\tmodel.add(Dense(500))\n",
    "\t\tmodel.add(Activation(activation))\n",
    "\n",
    "\t\t# define the second FC layer\n",
    "\t\tmodel.add(Dense(numClasses))\n",
    "\n",
    "\t\t# lastly, define the soft-max classifier\n",
    "\t\tmodel.add(Activation(\"softmax\"))\n",
    "\n",
    "\t\t# return the network architecture\n",
    "\t\treturn model\n",
    "\n",
    "\t@staticmethod\n",
    "\tdef KarpathyNet():\n",
    "\t\t# initialize the model\n",
    "\t\tmodel = Sequential()\n",
    "\n",
    "\t\t# define the first set of CONV => RELU => POOL layers\n",
    "\t\tmodel.add(Convolution2D(16, 5, 5, border_mode=\"same\",\n",
    "\t\t\tinput_shape=(numChannels, imgRows, imgCols)))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\tmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "\t\t# check to see if dropout should be applied to reduce overfitting\n",
    "\t\tif dropout:\n",
    "\t\t\tmodel.add(Dropout(0.25))\n",
    "\n",
    "\t\t# define the second set of CONV => RELU => POOL layers\n",
    "\t\tmodel.add(Convolution2D(20, 5, 5, border_mode=\"same\"))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\tmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "\t\t# check to see if dropout should be applied to reduce overfitting\n",
    "\t\tif dropout:\n",
    "\t\t\tmodel.add(Dropout(0.25))\n",
    "\n",
    "\t\t# define the third set of CONV => RELU => POOL layers\n",
    "\t\tmodel.add(Convolution2D(20, 5, 5, border_mode=\"same\"))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\tmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "\t\t# check to see if dropout should be applied to reduce overfitting\n",
    "\t\tif dropout:\n",
    "\t\t\tmodel.add(Dropout(0.5))\n",
    "\n",
    "\t\t# define the soft-max classifier\n",
    "\t\tmodel.add(Flatten())\n",
    "\t\tmodel.add(Dense(numClasses))\n",
    "\t\tmodel.add(Activation(\"softmax\"))\n",
    "\n",
    "\t\t# return the network architecture\n",
    "\t\treturn model\n",
    "\n",
    "\t@staticmethod\n",
    "\tdef MiniVGGNet():\n",
    "\t\t# initialize the model\n",
    "\t\tmodel = Sequential()\n",
    "\n",
    "\t\t# define the first set of CONV => RELU => CONV => RELU => POOL layers\n",
    "\t\tmodel.add(Convolution2D(32, 3, 3, border_mode=\"same\",\n",
    "\t\t\tinput_shape=(numChannels, imgRows, imgCols)))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\tmodel.add(Convolution2D(32, 3, 3))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\t\t# check to see if dropout should be applied to reduce overfitting\n",
    "\t\tif dropout:\n",
    "\t\t\tmodel.add(Dropout(0.25))\n",
    "\n",
    "\t\t# define the second set of CONV => RELU => CONV => RELU => POOL layers\n",
    "\t\tmodel.add(Convolution2D(64, 3, 3, border_mode=\"same\"))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\tmodel.add(Convolution2D(64, 3, 3))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\t\t# check to see if dropout should be applied to reduce overfitting\n",
    "\t\tif dropout:\n",
    "\t\t\tmodel.add(Dropout(0.25))\n",
    "\n",
    "\t\t# define the set of FC => RELU layers\n",
    "\t\tmodel.add(Flatten())\n",
    "\t\tmodel.add(Dense(512))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\n",
    "\t\t# check to see if dropout should be applied to reduce overfitting\n",
    "\t\tif dropout:\n",
    "\t\t\tmodel.add(Dropout(0.5))\n",
    "\n",
    "\t\t# define the soft-max classifier\n",
    "\t\tmodel.add(Dense(numClasses))\n",
    "\t\tmodel.add(Activation(\"softmax\"))\n",
    "\n",
    "\t\t# return the network architecture\n",
    "\t\treturn model"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
