{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2016 Bot \n",
    "\n",
    "### Overview\n",
    "- Introduction \n",
    "- Data ETL\n",
    "- Data Augmentation \n",
    "- Networks Architecture \n",
    "- Training \n",
    "- Model Averaging \n",
    "- Conclusion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os, sys, glob\n",
    "import numpy as np\n",
    "import cv2\n",
    "from skimage.io import imread\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import SGD\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from keras.models import model_from_json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Conf:\n",
    "    def __init__(self, confPath):\n",
    "        # load and store the configuration and update the object's dictionary\n",
    "        conf = json.loads(open(confPath).read())\n",
    "        self.__dict__.update(conf)\n",
    "\n",
    "    def __getitem__(self, k):\n",
    "        # return the value associated with the supplied key\n",
    "        return self.__dict__.get(k, None)\n",
    "    \n",
    "    \n",
    "def auto_resized(img,size):\n",
    "    '''size = (width,height)'''\n",
    "    size = tuple(size)\n",
    "    resize_img = cv2.resize(img, size, interpolation=cv2.INTER_LINEAR)\n",
    "    return resize_img\n",
    "\n",
    "def TrainFilePath(folderPath, constrain=None, **kargs):\n",
    "    '''\n",
    "    (1) Output filepath and calssName\n",
    "    (2) folderPath \n",
    "          --label_1\n",
    "           -- xxx.jpg\n",
    "    '''\n",
    "    assert folderPath[-1]!='/'\n",
    "    if constrain is None:\n",
    "        constrain = ('avi', 'mp4','png','jpg') \n",
    "    for (rootDir, dirNames, fileNames) in os.walk(folderPath):\n",
    "        for fileName in fileNames:\n",
    "            if fileName.split('.')[-1] in constrain:\n",
    "                yield (os.path.join(rootDir, fileName)) \n",
    "                \n",
    "#img_channels = 3\n",
    "def genTrX(filePath, resolution, img_channels=3):\n",
    "    assert type(resolution) == tuple\n",
    "    img = auto_resized(imread(filePath),resolution)  #conf['sliding_size']\n",
    "    if img_channels==1:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    elif img_channels==3:\n",
    "        img = img[:,:,:3]\n",
    "    return img\n",
    "                \n",
    "def load_training(folderList, img_rows, img_cols, img_channels):\n",
    "    TrY = []\n",
    "    TrX = []\n",
    "    TrY_template = np.eye(len(folderList))\n",
    "    for eyeId, folderPath in enumerate(folderList):\n",
    "        for imgPath in TrainFilePath(folderPath) :\n",
    "            TrY.append(TrY_template[eyeId])\n",
    "            TrX.append(genTrX(imgPath, (img_rows,img_cols), img_channels))\n",
    "    print (len(TrX))\n",
    "    return TrX, TrY\n",
    "\n",
    "def create_folderList(rootDir):\n",
    "    result=[]\n",
    "    for a in os.listdir(rootDir):\n",
    "        a = os.path.join(rootDir, a)\n",
    "        if os.path.isdir(a):\n",
    "            result.append(a) \n",
    "    return result\n",
    "\n",
    "\n",
    "def reshapeShuffle(TrX, TrY, img_rows, img_cols, img_channels):\n",
    "    trainX = np.asarray(TrX, dtype = np.uint8)\n",
    "    trainX = trainX.reshape(trainX.shape[0], img_channels, img_rows, img_cols)\n",
    "    trainX = trainX.astype('float32')\n",
    "    trainY = np.asarray(TrY, dtype = np.float32)\n",
    "    # shuffle\n",
    "    trainX , trainY = shuffle(trainX,trainY)\n",
    "    print ('Train_X : ',trainX.shape,'Train_Y' ,trainY.shape)\n",
    "    return trainX , trainY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116481\n"
     ]
    }
   ],
   "source": [
    "ROOT_Dir = 'D:\\\\2016bot_cv'\n",
    "\n",
    "img_rows= 48\n",
    "\n",
    "img_cols= 48\n",
    "\n",
    "img_channels=3\n",
    "\n",
    "folderList = create_folderList(ROOT_Dir)\n",
    "\n",
    "Train_X, Train_Y = load_training(folderList, img_rows, img_cols, img_channels)\n",
    "\n",
    "\n",
    "\n",
    "#TrainFilePath('D:\\2015')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Train_X : ', (116481L, 3L, 48L, 48L), 'Train_Y', (116481L, 12L))\n"
     ]
    }
   ],
   "source": [
    "train_X , train_Y = reshapeShuffle(Train_X, Train_Y, img_rows, img_cols, img_channels=img_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class ConvNetFactory:\n",
    "\tdef __init__(self):\n",
    "\t\tpass\n",
    "\n",
    "\t@staticmethod\n",
    "\tdef build(name, *args, **kargs):\n",
    "\t\t# define the network (i.e., string => function) mappings\n",
    "\t\tmappings = {\n",
    "\t\t\t\"shallownet\": ConvNetFactory.ShallowNet,\n",
    "\t\t\t\"lenet\": ConvNetFactory.LeNet,\n",
    "\t\t\t\"karpathynet\": ConvNetFactory.KarpathyNet,\n",
    "\t\t\t\"minivggnet\": ConvNetFactory.MiniVGGNet}\n",
    "\n",
    "\t\t# grab the builder function from the mappings dictionary\n",
    "\t\tbuilder = mappings.get(name, None)\n",
    "\n",
    "\t\t# if the builder is None, then there is not a function that can be used\n",
    "\t\t# to build to the network, so return None\n",
    "\t\tif builder is None:\n",
    "\t\t\treturn None\n",
    "\n",
    "\t\t# otherwise, build the network architecture\n",
    "\t\treturn builder(*args, **kargs)\n",
    "\n",
    "\t@staticmethod\n",
    "\tdef ShallowNet(numChannels, imgRows, imgCols, numClasses, **kwargs):\n",
    "\t\t# initialzie the model\n",
    "\t\tmodel = Sequential()\n",
    "\n",
    "\t\t# define the first (and only) CONV => RELU layer\n",
    "\t\tmodel.add(Convolution2D(32, 3, 3, border_mode=\"same\",\n",
    "\t\t\tinput_shape=(numChannels, imgRows, imgCols)))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\n",
    "\t\t# add a FC layer followed by the soft-max classifier\n",
    "\t\tmodel.add(Flatten())\n",
    "\t\tmodel.add(Dense(numClasses))\n",
    "\t\tmodel.add(Activation(\"softmax\"))\n",
    "\n",
    "\t\t# return the network architecture\n",
    "\t\treturn model\n",
    "\n",
    "\t@staticmethod\n",
    "\tdef LeNet(numChannels, imgRows, imgCols, numClasses, activation=\"tanh\", **kwargs):\n",
    "\t\t# initialize the model\n",
    "\t\tmodel = Sequential()\n",
    "\n",
    "\t\t# define the first set of CONV => ACTIVATION => POOL layers\n",
    "\t\tmodel.add(Convolution2D(20, 5, 5, border_mode=\"same\",\n",
    "\t\t\tinput_shape=(numChannels, imgRows, imgCols)))\n",
    "\t\tmodel.add(Activation(activation))\n",
    "\t\tmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "\t\t# define the second set of CONV => ACTIVATION => POOL layers\n",
    "\t\tmodel.add(Convolution2D(50, 5, 5, border_mode=\"same\"))\n",
    "\t\tmodel.add(Activation(activation))\n",
    "\t\tmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "\t\t# define the first FC => ACTIVATION layers\n",
    "\t\tmodel.add(Flatten())\n",
    "\t\tmodel.add(Dense(500))\n",
    "\t\tmodel.add(Activation(activation))\n",
    "\n",
    "\t\t# define the second FC layer\n",
    "\t\tmodel.add(Dense(numClasses))\n",
    "\n",
    "\t\t# lastly, define the soft-max classifier\n",
    "\t\tmodel.add(Activation(\"softmax\"))\n",
    "\n",
    "\t\t# return the network architecture\n",
    "\t\treturn model\n",
    "\n",
    "\t@staticmethod\n",
    "\tdef KarpathyNet():\n",
    "\t\t# initialize the model\n",
    "\t\tmodel = Sequential()\n",
    "\n",
    "\t\t# define the first set of CONV => RELU => POOL layers\n",
    "\t\tmodel.add(Convolution2D(16, 5, 5, border_mode=\"same\",\n",
    "\t\t\tinput_shape=(numChannels, imgRows, imgCols)))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\tmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "\t\t# check to see if dropout should be applied to reduce overfitting\n",
    "\t\tif dropout:\n",
    "\t\t\tmodel.add(Dropout(0.25))\n",
    "\n",
    "\t\t# define the second set of CONV => RELU => POOL layers\n",
    "\t\tmodel.add(Convolution2D(20, 5, 5, border_mode=\"same\"))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\tmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "\t\t# check to see if dropout should be applied to reduce overfitting\n",
    "\t\tif dropout:\n",
    "\t\t\tmodel.add(Dropout(0.25))\n",
    "\n",
    "\t\t# define the third set of CONV => RELU => POOL layers\n",
    "\t\tmodel.add(Convolution2D(20, 5, 5, border_mode=\"same\"))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\tmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "\t\t# check to see if dropout should be applied to reduce overfitting\n",
    "\t\tif dropout:\n",
    "\t\t\tmodel.add(Dropout(0.5))\n",
    "\n",
    "\t\t# define the soft-max classifier\n",
    "\t\tmodel.add(Flatten())\n",
    "\t\tmodel.add(Dense(numClasses))\n",
    "\t\tmodel.add(Activation(\"softmax\"))\n",
    "\n",
    "\t\t# return the network architecture\n",
    "\t\treturn model\n",
    "\n",
    "\t@staticmethod\n",
    "\tdef MiniVGGNet():\n",
    "\t\t# initialize the model\n",
    "\t\tmodel = Sequential()\n",
    "\n",
    "\t\t# define the first set of CONV => RELU => CONV => RELU => POOL layers\n",
    "\t\tmodel.add(Convolution2D(32, 3, 3, border_mode=\"same\",\n",
    "\t\t\tinput_shape=(numChannels, imgRows, imgCols)))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\tmodel.add(Convolution2D(32, 3, 3))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\t\t# check to see if dropout should be applied to reduce overfitting\n",
    "\t\tif dropout:\n",
    "\t\t\tmodel.add(Dropout(0.25))\n",
    "\n",
    "\t\t# define the second set of CONV => RELU => CONV => RELU => POOL layers\n",
    "\t\tmodel.add(Convolution2D(64, 3, 3, border_mode=\"same\"))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\tmodel.add(Convolution2D(64, 3, 3))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\t\t# check to see if dropout should be applied to reduce overfitting\n",
    "\t\tif dropout:\n",
    "\t\t\tmodel.add(Dropout(0.25))\n",
    "\n",
    "\t\t# define the set of FC => RELU layers\n",
    "\t\tmodel.add(Flatten())\n",
    "\t\tmodel.add(Dense(512))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\n",
    "\t\t# check to see if dropout should be applied to reduce overfitting\n",
    "\t\tif dropout:\n",
    "\t\t\tmodel.add(Dropout(0.5))\n",
    "\n",
    "\t\t# define the soft-max classifier\n",
    "\t\tmodel.add(Dense(numClasses))\n",
    "\t\tmodel.add(Activation(\"softmax\"))\n",
    "\n",
    "\t\t# return the network architecture\n",
    "\t\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'K' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-cce105f51c3d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mvertical_flip\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mrescale\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     dim_ordering=K.image_dim_ordering())\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'K' is not defined"
     ]
    }
   ],
   "source": [
    "gen_Img = ImageDataGenerator(featurewise_center=False,\n",
    "    samplewise_center=True,\n",
    "    featurewise_std_normalization=False,\n",
    "    samplewise_std_normalization=False,\n",
    "    zca_whitening=True,\n",
    "    rotation_range=180.,\n",
    "    width_shift_range=5.,\n",
    "    height_shift_range=5.,\n",
    "    shear_range=10.,\n",
    "    zoom_range=10.,\n",
    "    channel_shift_range=0.,\n",
    "    fill_mode='nearest',\n",
    "    cval=0.,\n",
    "    horizontal_flip=False,\n",
    "    vertical_flip=False,\n",
    "    rescale=None,\n",
    "    dim_ordering=K.image_dim_ordering())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
